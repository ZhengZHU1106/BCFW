{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4059877,"sourceType":"datasetVersion","datasetId":2395943}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport torch\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom tqdm import tqdm\n\ndef create_final_inference_file(data_path, output_file):\n    \"\"\"\n    ä¸€ä¸ªå®Œæ•´çš„æµç¨‹ï¼šåŠ è½½æ•°æ®ã€æ‹Ÿåˆå¤„ç†å™¨ã€æŒ‰æœ€ç»ˆè§„åˆ™é‡‡æ ·ã€å¤„ç†æ•°æ®ï¼Œå¹¶ä¿å­˜ä¸º.ptæ–‡ä»¶ã€‚\n    \"\"\"\n    # --- æ­¥éª¤ 1: åŠ è½½æ•°æ®å¹¶è¿›è¡Œæ¸…æ´—å’Œæ ‡ç­¾æ˜ å°„ ---\n    print(\"æ­¥éª¤ 1/5: åŠ è½½æ•°æ®å¹¶è¿›è¡Œæ¸…æ´—å’Œæ ‡ç­¾æ˜ å°„...\")\n    parquet_files = [os.path.join(data_path, f) for f in os.listdir(data_path)\n                     if f.endswith('.parquet')]\n    if not parquet_files:\n        raise FileNotFoundError(f\"é”™è¯¯ï¼šåœ¨è·¯å¾„ '{data_path}' ä¸‹æ²¡æœ‰æ‰¾åˆ°ä»»ä½• .parquet æ–‡ä»¶ã€‚\")\n    \n    df = pd.concat([pd.read_parquet(f) for f in tqdm(parquet_files, desc=\"åŠ è½½æ–‡ä»¶\")], ignore_index=True)\n    \n    # æ¸…ç†åˆ—åä¸­çš„ç©ºæ ¼\n    df.rename(columns={col: col.strip() for col in df.columns}, inplace=True)\n    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n    df.fillna(0, inplace=True)\n    \n    # æ¸…ç†åŸå§‹æ ‡ç­¾ä¸­çš„å¼‚å¸¸å­—ç¬¦\n    df['Label'] = df['Label'].astype(str).str.replace(r'[^a-zA-Z0-9\\s-]', '', regex=True).str.strip()\n\n    # æ˜ å°„åˆ°7ä¸ªä¸»è¦ç±»åˆ«\n    multi_class_mapping = {\n        'DoS Hulk': 'DoS', 'DoS GoldenEye': 'DoS', 'DoS slowloris': 'DoS',\n        'DoS Slowhttptest': 'DoS', 'FTP-Patator': 'Brute_Force',\n        'SSH-Patator': 'Brute_Force', 'Web Attack Brute Force': 'Web_Attack',\n        'Web Attack XSS': 'Web_Attack', 'Web Attack Sql Injection': 'Web_Attack',\n        'PortScan': 'PortScan', 'Bot': 'Bot', 'Infiltration': 'Rare_Attacks',\n        'Heartbleed': 'Rare_Attacks'\n    }\n    df['Multi_Label'] = df['Label'].replace(multi_class_mapping)\n\n    # å…³é”®æ­¥éª¤ï¼šåˆ é™¤æ¨¡å‹æœªå­¦ä¹ çš„å°ä¼—ç±»åˆ«\n    original_rows = len(df)\n    df = df[~df['Multi_Label'].isin(['Rare_Attacks'])]\n    print(f\"ç§»é™¤äº† {original_rows - len(df)} æ¡ 'Rare_Attacks' (Infiltration, Heartbleed) æ•°æ®ã€‚\")\n    \n    df.drop_duplicates(inplace=True)\n    print(\"æ•°æ®åŠ è½½å’Œé¢„å¤„ç†å®Œæˆã€‚\")\n\n    # --- æ­¥éª¤ 2: å‡†å¤‡å¹¶æ‹Ÿåˆæ•°æ®å¤„ç†å™¨ ---\n    print(\"\\næ­¥éª¤ 2/5: å‡†å¤‡å¹¶æ‹Ÿåˆæ•°æ®å¤„ç†å™¨ä»¥åŒ¹é…æ¨¡å‹...\")\n    feature_columns = [col for col in df.columns if col not in ['Label', 'Multi_Label']]\n    X = df[feature_columns]\n    y = df['Multi_Label']\n    \n    label_encoder = LabelEncoder()\n    label_encoder.fit(y)\n    print(f\"æ ‡ç­¾ç¼–ç å™¨æ‹Ÿåˆå®Œæˆï¼Œæœ€ç»ˆç±»åˆ«: {list(label_encoder.classes_)}\")\n\n    scaler = StandardScaler()\n    scaler.fit(X)\n    print(\"æ ‡å‡†åŒ–å¤„ç†å™¨(Scaler)æ‹Ÿåˆå®Œæˆã€‚\")\n    \n    # --- æ­¥éª¤ 3: ä»å¤„ç†åçš„æ•°æ®ä¸­æŒ‰æœ€ç»ˆè§„åˆ™é‡‡æ · ---\n    print(\"\\næ­¥éª¤ 3/5: æŒ‰æœ€ç»ˆè§„åˆ™è¿›è¡Œåˆ†å±‚é‡‡æ ·...\")\n    def get_sample_size(group_name):\n        return 130 if group_name == 'Benign' else 10\n\n    sampled_dfs = []\n    for group_name, group_df in df.groupby('Multi_Label'):\n        n = get_sample_size(group_name)\n        sampled_dfs.append(group_df.sample(n=n, random_state=42))\n        print(f\"  - ç±»åˆ« '{group_name}': æˆåŠŸæŠ½å– {n} æ¡æ•°æ®\")\n\n    sampled_df = pd.concat(sampled_dfs, ignore_index=True)\n    print(\"é‡‡æ ·å®Œæˆã€‚\")\n\n    # --- æ­¥éª¤ 4: å¤„ç†é‡‡æ ·æ•°æ®å¹¶è½¬æ¢ä¸ºTensor ---\n    print(\"\\næ­¥éª¤ 4/5: å¤„ç†é‡‡æ ·æ•°æ®å¹¶è½¬æ¢ä¸ºPyTorch Tensor...\")\n    x_sample_raw = sampled_df[feature_columns]\n    y_sample_str = sampled_df['Multi_Label']\n\n    x_sample_scaled = scaler.transform(x_sample_raw)\n    y_sample_encoded = label_encoder.transform(y_sample_str)\n    \n    features_tensor = torch.tensor(x_sample_scaled, dtype=torch.float32)\n    labels_tensor = torch.tensor(y_sample_encoded, dtype=torch.long)\n    print(f\"æ•°æ®å·²è½¬æ¢ä¸ºTensorã€‚ç‰¹å¾å½¢çŠ¶: {features_tensor.shape}, æ ‡ç­¾å½¢çŠ¶: {labels_tensor.shape}\")\n\n    # --- æ­¥éª¤ 5: ä¿å­˜ä¸º.ptæ–‡ä»¶ ---\n    print(f\"\\næ­¥éª¤ 5/5: ä¿å­˜åˆ°æ–‡ä»¶ '{output_file}'...\")\n    data_to_save = {\n        'features': features_tensor,\n        'labels': labels_tensor,\n        'class_names': list(label_encoder.classes_)\n    }\n    torch.save(data_to_save, output_file)\n    print(\"ä¿å­˜æˆåŠŸï¼\")\n\n# --- ä¸»ç¨‹åºå…¥å£ ---\nif __name__ == \"__main__\":\n    DATA_DIRECTORY = '/kaggle/input/cicids2017' \n    OUTPUT_FILE = 'inference_data.pt'\n\n    try:\n        create_final_inference_file(DATA_DIRECTORY, OUTPUT_FILE)\n        print(f\"\\nğŸ‰ æœ€ç»ˆæ–‡ä»¶ '{OUTPUT_FILE}' å·²æˆåŠŸç”Ÿæˆï¼\")\n        \n    except Exception as e:\n        print(f\"\\nâŒ å‘ç”Ÿé”™è¯¯: {e}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T12:36:55.575238Z","iopub.execute_input":"2025-08-24T12:36:55.575626Z","iopub.status.idle":"2025-08-24T12:37:17.127307Z","shell.execute_reply.started":"2025-08-24T12:36:55.575594Z","shell.execute_reply":"2025-08-24T12:37:17.126134Z"}},"outputs":[{"name":"stdout","text":"æ­¥éª¤ 1/5: åŠ è½½æ•°æ®å¹¶è¿›è¡Œæ¸…æ´—å’Œæ ‡ç­¾æ˜ å°„...\n","output_type":"stream"},{"name":"stderr","text":"åŠ è½½æ–‡ä»¶: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"ç§»é™¤äº† 47 æ¡ 'Rare_Attacks' (Infiltration, Heartbleed) æ•°æ®ã€‚\næ•°æ®åŠ è½½å’Œé¢„å¤„ç†å®Œæˆã€‚\n\næ­¥éª¤ 2/5: å‡†å¤‡å¹¶æ‹Ÿåˆæ•°æ®å¤„ç†å™¨ä»¥åŒ¹é…æ¨¡å‹...\næ ‡ç­¾ç¼–ç å™¨æ‹Ÿåˆå®Œæˆï¼Œæœ€ç»ˆç±»åˆ«: ['Benign', 'Bot', 'Brute_Force', 'DDoS', 'DoS', 'PortScan', 'Web Attack  Brute Force', 'Web Attack  Sql Injection', 'Web Attack  XSS']\næ ‡å‡†åŒ–å¤„ç†å™¨(Scaler)æ‹Ÿåˆå®Œæˆã€‚\n\næ­¥éª¤ 3/5: æŒ‰æœ€ç»ˆè§„åˆ™è¿›è¡Œåˆ†å±‚é‡‡æ ·...\n  - ç±»åˆ« 'Benign': æˆåŠŸæŠ½å– 130 æ¡æ•°æ®\n  - ç±»åˆ« 'Bot': æˆåŠŸæŠ½å– 10 æ¡æ•°æ®\n  - ç±»åˆ« 'Brute_Force': æˆåŠŸæŠ½å– 10 æ¡æ•°æ®\n  - ç±»åˆ« 'DDoS': æˆåŠŸæŠ½å– 10 æ¡æ•°æ®\n  - ç±»åˆ« 'DoS': æˆåŠŸæŠ½å– 10 æ¡æ•°æ®\n  - ç±»åˆ« 'PortScan': æˆåŠŸæŠ½å– 10 æ¡æ•°æ®\n  - ç±»åˆ« 'Web Attack  Brute Force': æˆåŠŸæŠ½å– 10 æ¡æ•°æ®\n  - ç±»åˆ« 'Web Attack  Sql Injection': æˆåŠŸæŠ½å– 10 æ¡æ•°æ®\n  - ç±»åˆ« 'Web Attack  XSS': æˆåŠŸæŠ½å– 10 æ¡æ•°æ®\né‡‡æ ·å®Œæˆã€‚\n\næ­¥éª¤ 4/5: å¤„ç†é‡‡æ ·æ•°æ®å¹¶è½¬æ¢ä¸ºPyTorch Tensor...\næ•°æ®å·²è½¬æ¢ä¸ºTensorã€‚ç‰¹å¾å½¢çŠ¶: torch.Size([210, 77]), æ ‡ç­¾å½¢çŠ¶: torch.Size([210])\n\næ­¥éª¤ 5/5: ä¿å­˜åˆ°æ–‡ä»¶ 'inference_data.pt'...\nä¿å­˜æˆåŠŸï¼\n\nğŸ‰ æœ€ç»ˆæ–‡ä»¶ 'inference_data.pt' å·²æˆåŠŸç”Ÿæˆï¼\n","output_type":"stream"}],"execution_count":3}]}