{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T13:37:21.631234Z",
     "iopub.status.busy": "2025-07-12T13:37:21.630916Z",
     "iopub.status.idle": "2025-07-12T14:09:54.377529Z",
     "shell.execute_reply": "2025-07-12T14:09:54.376445Z",
     "shell.execute_reply.started": "2025-07-12T13:37:21.631195Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在從路徑讀取數據: /kaggle/input/cicids2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "正在載入 Parquet 檔案: 100%|██████████| 8/8 [00:00<00:00,  8.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "數據載入完成，原始形狀: (2313810, 78)\n",
      "\n",
      "--- 正在進行數據清洗 ---\n",
      "移除了 84674 筆重複記錄。\n",
      "將 4 個稀有類別合併為 'Rare_Attack'\n",
      "\n",
      "--- 正在移除低方差/常數特徵 ---\n",
      "移除低方差特徵後，剩餘 65 個特徵。\n",
      "\n",
      "總共有 12 個類別\n",
      "\n",
      "成功選取了 64 個特徵進行訓練。\n",
      "\n",
      "所有數據預處理與特徵工程已完成！\n",
      "\n",
      "使用設備: cuda\n",
      "模型總參數數量: 351,130\n",
      "\n",
      "--- 開始訓練 Ensemble_Hybrid 模型 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 | 訓練損失: 0.6440 | 驗證損失: 0.5526 | 驗證準確率: 99.17%\n",
      "  ✓ 驗證損失降低，模型已保存\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 | 訓練損失: 0.5721 | 驗證損失: 0.5466 | 驗證準確率: 99.24%\n",
      "  ✓ 驗證損失降低，模型已保存\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 | 訓練損失: 0.5621 | 驗證損失: 0.5429 | 驗證準確率: 99.43%\n",
      "  ✓ 驗證損失降低，模型已保存\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 | 訓練損失: 0.5565 | 驗證損失: 0.5414 | 驗證準確率: 99.48%\n",
      "  ✓ 驗證損失降低，模型已保存\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 | 訓練損失: 0.5519 | 驗證損失: 0.5401 | 驗證準確率: 99.49%\n",
      "  ✓ 驗證損失降低，模型已保存\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 | 訓練損失: 0.5497 | 驗證損失: 0.5395 | 驗證準確率: 99.51%\n",
      "  ✓ 驗證損失降低，模型已保存\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 | 訓練損失: 0.5482 | 驗證損失: 0.5390 | 驗證準確率: 99.52%\n",
      "  ✓ 驗證損失降低，模型已保存\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 | 訓練損失: 0.5471 | 驗證損失: 0.5385 | 驗證準確率: 99.53%\n",
      "  ✓ 驗證損失降低，模型已保存\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 | 訓練損失: 0.5463 | 驗證損失: 0.5383 | 驗證準確率: 99.51%\n",
      "  ✓ 驗證損失降低，模型已保存\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 | 訓練損失: 0.5455 | 驗證損失: 0.5378 | 驗證準確率: 99.56%\n",
      "  ✓ 驗證損失降低，模型已保存\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 | 訓練損失: 0.5411 | 驗證損失: 0.5376 | 驗證準確率: 99.55%\n",
      "  ✓ 驗證損失降低，模型已保存\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 | 訓練損失: 0.5401 | 驗證損失: 0.5373 | 驗證準確率: 99.57%\n",
      "  ✓ 驗證損失降低，模型已保存\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 | 訓練損失: 0.5396 | 驗證損失: 0.5383 | 驗證準確率: 99.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 | 訓練損失: 0.5392 | 驗證損失: 0.5369 | 驗證準確率: 99.57%\n",
      "  ✓ 驗證損失降低，模型已保存\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 | 訓練損失: 0.5388 | 驗證損失: 0.5369 | 驗證準確率: 99.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 | 訓練損失: 0.5385 | 驗證損失: 0.5366 | 驗證準確率: 99.58%\n",
      "  ✓ 驗證損失降低，模型已保存\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 | 訓練損失: 0.5383 | 驗證損失: 0.5367 | 驗證準確率: 99.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30 | 訓練損失: 0.5381 | 驗證損失: 0.5364 | 驗證準確率: 99.61%\n",
      "  ✓ 驗證損失降低，模型已保存\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 | 訓練損失: 0.5378 | 驗證損失: 0.5363 | 驗證準確率: 99.61%\n",
      "  ✓ 驗證損失降低，模型已保存\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30 | 訓練損失: 0.5378 | 驗證損失: 0.5362 | 驗證準確率: 99.62%\n",
      "  ✓ 驗證損失降低，模型已保存\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 | 訓練損失: 0.5376 | 驗證損失: 0.5360 | 驗證準確率: 99.62%\n",
      "  ✓ 驗證損失降低，模型已保存\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 | 訓練損失: 0.5375 | 驗證損失: 0.5362 | 驗證準確率: 99.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 | 訓練損失: 0.5373 | 驗證損失: 0.5359 | 驗證準確率: 99.63%\n",
      "  ✓ 驗證損失降低，模型已保存\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30 | 訓練損失: 0.5372 | 驗證損失: 0.5359 | 驗證準確率: 99.61%\n",
      "  ✓ 驗證損失降低，模型已保存\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30 | 訓練損失: 0.5371 | 驗證損失: 0.5358 | 驗證準確率: 99.63%\n",
      "  ✓ 驗證損失降低，模型已保存\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30 | 訓練損失: 0.5370 | 驗證損失: 0.5357 | 驗證準確率: 99.64%\n",
      "  ✓ 驗證損失降低，模型已保存\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30 | 訓練損失: 0.5369 | 驗證損失: 0.5356 | 驗證準確率: 99.64%\n",
      "  ✓ 驗證損失降低，模型已保存\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30 | 訓練損失: 0.5368 | 驗證損失: 0.5355 | 驗證準確率: 99.63%\n",
      "  ✓ 驗證損失降低，模型已保存\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30 | 訓練損失: 0.5367 | 驗證損失: 0.5357 | 驗證準確率: 99.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30 | 訓練損失: 0.5366 | 驗證損失: 0.5360 | 驗證準確率: 99.59%\n",
      "\n",
      "訓練完成！\n",
      "\n",
      "--- 載入最佳模型進行最終評估 ---\n",
      "成功載入來自 Epoch 28 的最佳模型。\n",
      "\n",
      "--- 正在評估 Ensemble_Hybrid 模型 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "評估測試集: 100%|██████████| 871/871 [00:06<00:00, 144.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉🎉🎉 --- 最終評估報告 (測試集) --- 🎉🎉🎉\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                 Benign     0.9978    0.9979    0.9979    378533\n",
      "                    Bot     0.6020    0.8432    0.7025       287\n",
      "                   DDoS     0.9983    0.9991    0.9987     25603\n",
      "          DoS GoldenEye     0.9898    0.9893    0.9895      2054\n",
      "               DoS Hulk     0.9874    0.9918    0.9896     34569\n",
      "       DoS Slowhttptest     0.8907    0.9895    0.9375      1046\n",
      "          DoS slowloris     0.9861    0.9870    0.9865      1077\n",
      "            FTP-Patator     0.9899    0.9933    0.9916      1186\n",
      "               PortScan     0.9248    0.9437    0.9342       391\n",
      "            Rare_Attack     1.0000    0.0278    0.0541       144\n",
      "            SSH-Patator     0.9983    0.9208    0.9580       644\n",
      "Web Attack  Brute Force     1.0000    0.0986    0.1796       294\n",
      "\n",
      "               accuracy                         0.9962    445828\n",
      "              macro avg     0.9471    0.8152    0.8100    445828\n",
      "           weighted avg     0.9964    0.9962    0.9959    445828\n",
      "\n",
      "\n",
      "--- 正在保存完整的模型文件包至 /kaggle/working/ensemble_hybrid_model_package/ ---\n",
      "✓ 已保存 model.pth\n",
      "✓ 已保存 scaler.pkl\n",
      "✓ 已保存 label_encoder.pkl\n",
      "✓ 已保存 feature_selector.pkl\n",
      "✓ 已保存 selected_features.json\n",
      "✓ 已保存 model_info.json\n",
      "\n",
      "✅ 訓練與模型文件打包全部完成！\n",
      "\n",
      "🎉 腳本執行成功！\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Ensemble_Hybrid 完整 PyTorch 訓練與部署文件打包腳本\n",
    "#\n",
    "# 結合了 Ensemble_Hybrid 的高性能模型與生產級的模型文件打包功能。\n",
    "#\n",
    "# 主要特點:\n",
    "# 1. 使用 Ensemble_Hybrid 複雜模型進行訓練。\n",
    "# 2. 包含完整的數據清洗、特徵工程與模型穩定性修復。\n",
    "# 3. 在訓練結束後，自動打包所有部署所需文件：\n",
    "#    - model.pth (模型權重)\n",
    "#    - scaler.pkl (數據縮放器)\n",
    "#    - label_encoder.pkl (標籤編碼器)\n",
    "#    - feature_selector.pkl (特徵選擇器)\n",
    "#    - selected_features.json (所選特徵列表)\n",
    "#    - model_info.json (模型元數據)\n",
    "# ===================================================================\n",
    "\n",
    "# 1. 導入必要的庫\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.amp\n",
    "from torch.amp import GradScaler\n",
    "\n",
    "# 引入 sklearn 相關函式庫\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 引入 tqdm 函式庫來顯示進度條\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ===================================================================\n",
    "# 2. 模型組件定義\n",
    "# ===================================================================\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"殘差塊 - 改善梯度流動\"\"\"\n",
    "    def __init__(self, dim, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.BatchNorm1d(dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.BatchNorm1d(dim)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.block(x)\n",
    "        out = out + residual\n",
    "        return F.relu(self.dropout(out))\n",
    "\n",
    "class SelfAttentionBranch(nn.Module):\n",
    "    \"\"\"自注意力分支\"\"\"\n",
    "    def __init__(self, input_dim, num_classes, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.attention_dim = min(64, input_dim)\n",
    "        self.query = nn.Linear(input_dim, self.attention_dim)\n",
    "        self.key = nn.Linear(input_dim, self.attention_dim)\n",
    "        self.value = nn.Linear(input_dim, self.attention_dim)\n",
    "        self.output_projection = nn.Linear(self.attention_dim, input_dim)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(module.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        v = self.value(x)\n",
    "        attention_scores = torch.sum(q * k, dim=1, keepdim=True)\n",
    "        attention_weights = torch.sigmoid(attention_scores)\n",
    "        attention_weights = torch.clamp(attention_weights, min=1e-8, max=1.0)\n",
    "        attended = attention_weights * v\n",
    "        projected = self.output_projection(attended)\n",
    "        return self.classifier(projected)\n",
    "\n",
    "class FeatureInteractionBranch(nn.Module):\n",
    "    \"\"\"特徵交互分支\"\"\"\n",
    "    def __init__(self, input_dim, num_classes, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.interaction_dim = min(8, input_dim // 8)\n",
    "        self.feature_embeddings = nn.Linear(input_dim, self.interaction_dim)\n",
    "        self.interaction_output_dim = (self.interaction_dim * (self.interaction_dim - 1)) // 2\n",
    "        if self.interaction_output_dim == 0:\n",
    "            self.interaction_output_dim = 1\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(input_dim + self.interaction_output_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(module.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embeddings = torch.tanh(self.feature_embeddings(x))\n",
    "        interactions = []\n",
    "        if self.interaction_dim > 1:\n",
    "            for i in range(self.interaction_dim):\n",
    "                for j in range(i + 1, self.interaction_dim):\n",
    "                    interaction = embeddings[:, i] * embeddings[:, j]\n",
    "                    interactions.append(interaction.unsqueeze(1))\n",
    "        \n",
    "        if interactions:\n",
    "            interaction_features = torch.cat(interactions, dim=1)\n",
    "        else:\n",
    "            interaction_features = torch.zeros(x.size(0), 1, device=x.device)\n",
    "        \n",
    "        combined_features = torch.cat([x, interaction_features], dim=1)\n",
    "        return self.classifier(combined_features)\n",
    "\n",
    "class Ensemble_Hybrid(nn.Module):\n",
    "    \"\"\"集成混合網絡\"\"\"\n",
    "    def __init__(self, input_dim, num_classes=15, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.deep_branch = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, 128), nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        self.wide_branch = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512), nn.BatchNorm1d(512), nn.ReLU(), nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        self.res_branch = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128), nn.BatchNorm1d(128), nn.ReLU(),\n",
    "            ResidualBlock(128, dropout_rate),\n",
    "            ResidualBlock(128, dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        self.attention_branch = SelfAttentionBranch(input_dim, num_classes, dropout_rate)\n",
    "        self.interaction_branch = FeatureInteractionBranch(input_dim, num_classes, dropout_rate)\n",
    "        \n",
    "        self.weight_net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32), nn.ReLU(), nn.Dropout(dropout_rate),\n",
    "            nn.Linear(32, 5), nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.final_fusion = nn.Sequential(\n",
    "            nn.Linear(num_classes * 5, 128), nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        self.global_weights = nn.Parameter(torch.ones(5) / 5)\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None: nn.init.constant_(module.bias, 0)\n",
    "            elif isinstance(module, nn.BatchNorm1d):\n",
    "                nn.init.constant_(module.weight, 1)\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "    \n",
    "    def forward(self, x, return_intermediate=False):\n",
    "        if torch.isnan(x).any() or torch.isinf(x).any():\n",
    "            x = torch.nan_to_num(x, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "        \n",
    "        outputs = [\n",
    "            self.deep_branch(x), self.wide_branch(x), self.res_branch(x),\n",
    "            self.attention_branch(x), self.interaction_branch(x)\n",
    "        ]\n",
    "        \n",
    "        for i, out in enumerate(outputs):\n",
    "            if torch.isnan(out).any() or torch.isinf(out).any():\n",
    "                outputs[i] = torch.nan_to_num(out, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "        \n",
    "        deep_out, wide_out, res_out, att_out, inter_out = outputs\n",
    "        \n",
    "        adaptive_weights = torch.clamp(self.weight_net(x), min=1e-8, max=1.0)\n",
    "        global_weights = torch.clamp(F.softmax(self.global_weights, dim=0), min=1e-8, max=1.0)\n",
    "        \n",
    "        outputs_stack = torch.stack(outputs, dim=2)\n",
    "        \n",
    "        weighted_output_adaptive = torch.sum(outputs_stack * adaptive_weights.unsqueeze(1), dim=2)\n",
    "        weighted_output_global = torch.sum(outputs_stack * global_weights.unsqueeze(0).unsqueeze(0), dim=2)\n",
    "        weighted_output = 0.6 * weighted_output_adaptive + 0.4 * weighted_output_global\n",
    "        \n",
    "        concatenated = torch.cat(outputs, dim=1)\n",
    "        final_output = self.final_fusion(concatenated)\n",
    "        \n",
    "        ensemble_output = 0.7 * final_output + 0.3 * weighted_output\n",
    "        \n",
    "        if torch.isnan(ensemble_output).any() or torch.isinf(ensemble_output).any():\n",
    "            ensemble_output = torch.nan_to_num(ensemble_output, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "            \n",
    "        if return_intermediate:\n",
    "            return {\n",
    "                'ensemble': ensemble_output, 'final_fusion': final_output,\n",
    "                'weighted': weighted_output, 'branches': tuple(outputs),\n",
    "                'weights': (adaptive_weights, global_weights)\n",
    "            }\n",
    "        return ensemble_output\n",
    "\n",
    "# ===================================================================\n",
    "# 3. 損失函數\n",
    "# ===================================================================\n",
    "\n",
    "class EnsembleLoss(nn.Module):\n",
    "    \"\"\"集成損失函數\"\"\"\n",
    "    def __init__(self, num_classes, alpha=0.7, label_smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def forward(self, outputs, targets):\n",
    "        if isinstance(outputs, dict):\n",
    "            main_loss = self.criterion(outputs['ensemble'], targets)\n",
    "            \n",
    "            branch_losses = []\n",
    "            for branch_out in outputs['branches']:\n",
    "                if not (torch.isnan(branch_out).any() or torch.isinf(branch_out).any()):\n",
    "                    branch_losses.append(self.criterion(branch_out, targets))\n",
    "            \n",
    "            auxiliary_loss = torch.mean(torch.stack(branch_losses)) if branch_losses else torch.tensor(0.0, device=targets.device)\n",
    "            fusion_loss = self.criterion(outputs['final_fusion'], targets)\n",
    "            \n",
    "            if torch.isnan(main_loss): main_loss = torch.tensor(0.0, device=targets.device)\n",
    "            if torch.isnan(auxiliary_loss): auxiliary_loss = torch.tensor(0.0, device=targets.device)\n",
    "            if torch.isnan(fusion_loss): fusion_loss = torch.tensor(0.0, device=targets.device)\n",
    "            \n",
    "            total_loss = (self.alpha * main_loss + \n",
    "                          (1 - self.alpha) * 0.7 * auxiliary_loss + \n",
    "                          (1 - self.alpha) * 0.3 * fusion_loss)\n",
    "            return total_loss\n",
    "        else:\n",
    "            return self.criterion(outputs, targets)\n",
    "\n",
    "# ===================================================================\n",
    "# 4. 訓練與評估函數\n",
    "# ===================================================================\n",
    "\n",
    "def train_ensemble_model(model, train_loader, val_loader, device, num_epochs, patience, use_multi_gpu):\n",
    "    \"\"\"訓練函數\"\"\"\n",
    "    print(\"\\n--- 開始訓練 Ensemble_Hybrid 模型 ---\")\n",
    "    actual_model = model.module if use_multi_gpu else model\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=3)\n",
    "    criterion = EnsembleLoss(num_classes=actual_model.num_classes, label_smoothing=0.1)\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    model_output_dir = \"/kaggle/working/ensemble_hybrid_model_checkpoint\"\n",
    "    os.makedirs(model_output_dir, exist_ok=True)\n",
    "    best_model_path = os.path.join(model_output_dir, \"best_ensemble_model.pth\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [訓練]\", leave=False)\n",
    "        \n",
    "        for batch_idx, (inputs, labels) in enumerate(train_pbar):\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            if torch.isnan(inputs).any():\n",
    "                inputs = torch.nan_to_num(inputs, nan=0.0)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            outputs = model(inputs, return_intermediate=(epoch < 10))\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            if torch.isnan(loss): continue\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            train_pbar.set_postfix({'Loss': f'{loss.item():.4f}'})\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        model.eval()\n",
    "        total_val_loss, val_correct, val_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "                if torch.isnan(inputs).any():\n",
    "                    inputs = torch.nan_to_num(inputs, nan=0.0)\n",
    "                outputs = model(inputs)\n",
    "                if isinstance(outputs, dict): outputs = outputs['ensemble']\n",
    "                if torch.isnan(outputs).any(): continue\n",
    "                    \n",
    "                loss = criterion(outputs, labels)\n",
    "                if not torch.isnan(loss): total_val_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        avg_val_loss = total_val_loss / len(val_loader) if len(val_loader) > 0 else float('inf')\n",
    "        val_accuracy = 100 * val_correct / val_total if val_total > 0 else 0\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | 訓練損失: {avg_train_loss:.4f} | 驗證損失: {avg_val_loss:.4f} | 驗證準確率: {val_accuracy:.2f}%\")\n",
    "        \n",
    "        if avg_val_loss < best_val_loss and not np.isnan(avg_val_loss):\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            model_state_dict = model.module.state_dict() if use_multi_gpu else model.state_dict()\n",
    "            torch.save({\n",
    "                'model_state_dict': model_state_dict, 'epoch': epoch,\n",
    "                'val_loss': avg_val_loss, 'val_accuracy': val_accuracy\n",
    "            }, best_model_path)\n",
    "            print(f\"  ✓ 驗證損失降低，模型已保存\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"\\n早停機制觸發：在 {patience} 個週期內無改進。\")\n",
    "                break\n",
    "    \n",
    "    print(\"\\n訓練完成！\")\n",
    "    return best_model_path\n",
    "\n",
    "def evaluate_ensemble_model(model, test_loader, device, label_encoder):\n",
    "    \"\"\"評估函數\"\"\"\n",
    "    print(\"\\n--- 正在評估 Ensemble_Hybrid 模型 ---\")\n",
    "    model.eval()\n",
    "    y_pred_list, y_true_list = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=\"評估測試集\"):\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            if torch.isnan(inputs).any():\n",
    "                inputs = torch.nan_to_num(inputs, nan=0.0)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            if isinstance(outputs, dict): outputs = outputs['ensemble']\n",
    "            if torch.isnan(outputs).any():\n",
    "                outputs = torch.nan_to_num(outputs, nan=0.0)\n",
    "\n",
    "            _, predicted_labels = torch.max(outputs, 1)\n",
    "            y_pred_list.extend(predicted_labels.cpu().numpy())\n",
    "            y_true_list.extend(labels.cpu().numpy())\n",
    "            \n",
    "    report = classification_report(\n",
    "        y_true_list, y_pred_list,\n",
    "        target_names=[str(cls) for cls in label_encoder.classes_],\n",
    "        zero_division=0, digits=4\n",
    "    )\n",
    "    return report\n",
    "\n",
    "# ===================================================================\n",
    "# 5. 新增：保存所有模型文件的函數\n",
    "# ===================================================================\n",
    "def save_model_files(model, scaler, label_encoder, feature_selector, selected_features, \n",
    "                    model_dir='/kaggle/working/ensemble_hybrid_model_package'):\n",
    "    \"\"\"保存所有用於部署的必要文件\"\"\"\n",
    "    print(f\"\\n--- 正在保存完整的模型文件包至 {model_dir}/ ---\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    actual_model = model.module if isinstance(model, nn.DataParallel) else model\n",
    "    \n",
    "    # 1. 保存 PyTorch 模型\n",
    "    torch.save({\n",
    "        'model_state_dict': actual_model.state_dict(),\n",
    "        'model_architecture': 'Ensemble_Hybrid',\n",
    "        'input_dim': actual_model.input_dim,\n",
    "        'num_classes': actual_model.num_classes,\n",
    "    }, os.path.join(model_dir, 'model.pth'))\n",
    "    print(\"✓ 已保存 model.pth\")\n",
    "    \n",
    "    # 2. 保存 scikit-learn 物件\n",
    "    joblib.dump(scaler, os.path.join(model_dir, 'scaler.pkl'))\n",
    "    print(\"✓ 已保存 scaler.pkl\")\n",
    "    \n",
    "    joblib.dump(label_encoder, os.path.join(model_dir, 'label_encoder.pkl'))\n",
    "    print(\"✓ 已保存 label_encoder.pkl\")\n",
    "    \n",
    "    joblib.dump(feature_selector, os.path.join(model_dir, 'feature_selector.pkl'))\n",
    "    print(\"✓ 已保存 feature_selector.pkl\")\n",
    "    \n",
    "    # 3. 保存特徵列表為 JSON\n",
    "    with open(os.path.join(model_dir, 'selected_features.json'), 'w') as f:\n",
    "        json.dump(selected_features, f, indent=2)\n",
    "    print(\"✓ 已保存 selected_features.json\")\n",
    "    \n",
    "    # 4. 保存模型元數據\n",
    "    model_info = {\n",
    "        'dataset': 'CIC-IDS2017',\n",
    "        'model_type': 'PyTorch Ensemble_Hybrid',\n",
    "        'num_features_selected': len(selected_features),\n",
    "        'num_classes': len(label_encoder.classes_),\n",
    "        'classes': label_encoder.classes_.tolist(),\n",
    "        'preprocessing_steps': {\n",
    "            'variance_threshold': 0.001,\n",
    "            'feature_selection_method': 'SelectKBest',\n",
    "            'k_features': len(selected_features),\n",
    "            'scaling_method': 'StandardScaler'\n",
    "        }\n",
    "    }\n",
    "    with open(os.path.join(model_dir, 'model_info.json'), 'w') as f:\n",
    "        json.dump(model_info, f, indent=2)\n",
    "    print(\"✓ 已保存 model_info.json\")\n",
    "\n",
    "# ===================================================================\n",
    "# 6. 主執行函數 (修改版 - 整合所有功能)\n",
    "# ===================================================================\n",
    "def main():\n",
    "    \"\"\"主執行流程\"\"\"\n",
    "    # --- 設置與環境檢查 ---\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    seed = 42\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    # --- 數據載入 ---\n",
    "    data_path = '/kaggle/input/cicids2017'\n",
    "    print(f\"正在從路徑讀取數據: {data_path}\")\n",
    "    if not os.path.exists(data_path):\n",
    "        raise FileNotFoundError(f\"錯誤：找不到數據路徑 '{data_path}'。\")\n",
    "    \n",
    "    parquet_files = [os.path.join(data_path, f) for f in os.listdir(data_path) if f.endswith('.parquet')]\n",
    "    if not parquet_files:\n",
    "        raise FileNotFoundError(f\"錯誤：路徑 '{data_path}' 中找不到 .parquet 檔案。\")\n",
    "\n",
    "    df_list = [pd.read_parquet(file) for file in tqdm(parquet_files, desc=\"正在載入 Parquet 檔案\")]\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    del df_list; gc.collect()\n",
    "    print(f\"數據載入完成，原始形狀: {df.shape}\")\n",
    "\n",
    "    # --- 數據預處理 ---\n",
    "    label_column = 'Label' if 'Label' in df.columns else ' Label'\n",
    "    df.rename(columns={col: col.strip() for col in df.columns}, inplace=True)\n",
    "    label_column = label_column.strip()\n",
    "\n",
    "    print(\"\\n--- 正在進行數據清洗 ---\")\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_columns:\n",
    "        if col != label_column:\n",
    "            q99 = df[col].quantile(0.99)\n",
    "            q01 = df[col].quantile(0.01)\n",
    "            df[col] = df[col].clip(lower=q01, upper=q99)\n",
    "\n",
    "    initial_rows = df.shape[0]\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(f\"移除了 {initial_rows - df.shape[0]} 筆重複記錄。\")\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    X = df.drop(columns=[label_column])\n",
    "    y = df[label_column].copy()\n",
    "    del df; gc.collect()\n",
    "\n",
    "    y = y.str.replace(r'[^a-zA-Z0-9\\s-]', '', regex=True).str.strip()\n",
    "    label_counts = y.value_counts()\n",
    "    threshold = 1000\n",
    "    rare_labels = label_counts[label_counts < threshold].index\n",
    "    if not rare_labels.empty:\n",
    "        print(f\"將 {len(rare_labels)} 個稀有類別合併為 'Rare_Attack'\")\n",
    "        y.replace(rare_labels, 'Rare_Attack', inplace=True)\n",
    "    \n",
    "    print(\"\\n--- 正在移除低方差/常數特徵 ---\")\n",
    "    var_selector = VarianceThreshold(threshold=0.001)\n",
    "    X_filtered = var_selector.fit_transform(X)\n",
    "    retained_columns = X.columns[var_selector.get_support()]\n",
    "    X = pd.DataFrame(X_filtered, index=X.index, columns=retained_columns)\n",
    "    print(f\"移除低方差特徵後，剩餘 {X.shape[1]} 個特徵。\")\n",
    "\n",
    "    X = X.fillna(0)\n",
    "    X = X.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    print(f\"\\n總共有 {num_classes} 個類別\")\n",
    "\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X, y_encoded, test_size=0.2, random_state=seed, stratify=y_encoded\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=0.2, random_state=seed, stratify=y_train_val\n",
    "    )\n",
    "\n",
    "    # 特徵選擇\n",
    "    K_FEATURES = min(64, X_train.shape[1])\n",
    "    selector = SelectKBest(f_classif, k=K_FEATURES)\n",
    "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "    X_val_selected = selector.transform(X_val)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "    \n",
    "    selected_features_mask = selector.get_support()\n",
    "    selected_features = X_train.columns[selected_features_mask].tolist()\n",
    "    print(f\"\\n成功選取了 {len(selected_features)} 個特徵進行訓練。\")\n",
    "\n",
    "    # 標準化\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "    X_val_scaled = scaler.transform(X_val_selected)\n",
    "    X_test_scaled = scaler.transform(X_test_selected)\n",
    "    \n",
    "    X_train_scaled = np.nan_to_num(X_train_scaled, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "    X_val_scaled = np.nan_to_num(X_val_scaled, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "    X_test_scaled = np.nan_to_num(X_test_scaled, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "    \n",
    "    print(\"\\n所有數據預處理與特徵工程已完成！\")\n",
    "\n",
    "    # --- DataLoader 準備 ---\n",
    "    batch_size = 512\n",
    "    num_workers = min(2, os.cpu_count())\n",
    "    \n",
    "    train_dataset = TensorDataset(torch.from_numpy(X_train_scaled).float(), torch.from_numpy(y_train).long())\n",
    "    val_dataset = TensorDataset(torch.from_numpy(X_val_scaled).float(), torch.from_numpy(y_val).long())\n",
    "    test_dataset = TensorDataset(torch.from_numpy(X_test_scaled).float(), torch.from_numpy(y_test).long())\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True, persistent_workers=True if num_workers > 0 else False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True, persistent_workers=True if num_workers > 0 else False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True, persistent_workers=True if num_workers > 0 else False)\n",
    "\n",
    "    # --- 模型初始化與訓練 ---\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"\\n使用設備: {device}\")\n",
    "    \n",
    "    model = Ensemble_Hybrid(input_dim=K_FEATURES, num_classes=num_classes, dropout_rate=0.2)\n",
    "    \n",
    "    use_multi_gpu = torch.cuda.device_count() > 1\n",
    "    if use_multi_gpu:\n",
    "        print(f\"\\n檢測到 {torch.cuda.device_count()} 個GPU，啟用並行訓練。\")\n",
    "        model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    \n",
    "    print(f\"模型總參數數量: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "    best_model_path = train_ensemble_model(\n",
    "        model=model, train_loader=train_loader, val_loader=val_loader,\n",
    "        device=device, num_epochs=30, patience=8, use_multi_gpu=use_multi_gpu\n",
    "    )\n",
    "\n",
    "    # --- 模型評估與文件保存 ---\n",
    "    del model, train_loader, val_loader; gc.collect()\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"\\n--- 載入最佳模型進行最終評估 ---\")\n",
    "    final_model = Ensemble_Hybrid(input_dim=K_FEATURES, num_classes=num_classes, dropout_rate=0.2)\n",
    "    checkpoint = torch.load(best_model_path, map_location=device)\n",
    "    \n",
    "    # 兼容單GPU和多GPU保存的模型\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "    if use_multi_gpu and not list(state_dict.keys())[0].startswith('module.'):\n",
    "        state_dict = {'module.' + k: v for k, v in state_dict.items()}\n",
    "    elif not use_multi_gpu and list(state_dict.keys())[0].startswith('module.'):\n",
    "        state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "\n",
    "    final_model.load_state_dict(state_dict)\n",
    "\n",
    "    if use_multi_gpu:\n",
    "        final_model = nn.DataParallel(final_model)\n",
    "    final_model.to(device)\n",
    "    print(f\"成功載入來自 Epoch {checkpoint['epoch']+1} 的最佳模型。\")\n",
    "\n",
    "    report = evaluate_ensemble_model(\n",
    "        final_model, test_loader, device, label_encoder\n",
    "    )\n",
    "\n",
    "    print(\"\\n🎉🎉🎉 --- 最終評估報告 (測試集) --- 🎉🎉🎉\")\n",
    "    print(report)\n",
    "\n",
    "    # --- 保存所有部署所需的文件 ---\n",
    "    save_model_files(\n",
    "        model=final_model,\n",
    "        scaler=scaler,\n",
    "        label_encoder=label_encoder,\n",
    "        feature_selector=selector,\n",
    "        selected_features=selected_features\n",
    "    )\n",
    "    \n",
    "    print(\"\\n✅ 訓練與模型文件打包全部完成！\")\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "# 7. 程序入口\n",
    "# ===================================================================\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        main()\n",
    "        print(\"\\n🎉 腳本執行成功！\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ 執行過程中出現錯誤: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2395943,
     "sourceId": 4059877,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
