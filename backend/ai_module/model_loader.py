"""
AIæ¨¡å‹åŠ è½½å’Œæ¨ç†æ¨¡å—
"""

import torch
import pickle
import json
import numpy as np
from pathlib import Path
import logging
from typing import Dict, List, Tuple, Optional
try:
    from ..config import AI_MODEL_CONFIG, THREAT_THRESHOLDS
except ImportError:
    # å¤„ç†ç›´æ¥è¿è¡Œæ—¶çš„å¯¼å…¥é—®é¢˜
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.dirname(__file__)))
    from config import AI_MODEL_CONFIG, THREAT_THRESHOLDS

# å¯¼å…¥æ–°çš„åˆ†å±‚Transformeræ¨¡å‹
import sys
sys.path.append(str(AI_MODEL_CONFIG['new_model_package_dir']))
from model_loader import HierarchicalTransformerIDSLoader

logger = logging.getLogger(__name__)

class ThreatDetectionModel:
    """å¨èƒæ£€æµ‹æ¨¡å‹ç®¡ç†å™¨ - ä½¿ç”¨æ–°çš„åˆ†å±‚Transformeræ¨¡å‹"""
    
    def __init__(self):
        # æ–°æ¨¡å‹ç›¸å…³å±æ€§
        self.transformer_loader = None
        self.new_model_info = None
        
        # å…¼å®¹æ€§å±æ€§ï¼ˆä¿æŒæ¥å£ä¸€è‡´ï¼‰
        self.model = None
        self.scaler = None
        self.feature_selector = None
        self.label_encoder = None
        self.model_info = None
        self.selected_features = None
        self.inference_data = None
        
        self._load_new_transformer_model()
    
    def _load_new_transformer_model(self):
        """åŠ è½½æ–°çš„åˆ†å±‚Transformeræ¨¡å‹"""
        try:
            logger.info("ğŸ¤– å¼€å§‹åŠ è½½æ–°çš„åˆ†å±‚Transformeræ¨¡å‹...")
            
            # åŠ è½½æ–°çš„Transformeræ¨¡å‹
            model_package_path = str(AI_MODEL_CONFIG['new_model_package_dir'])
            self.transformer_loader = HierarchicalTransformerIDSLoader(model_package_path)
            
            # è·å–æ¨¡å‹ä¿¡æ¯
            self.new_model_info = self.transformer_loader.get_model_info()
            
            # ä¸ºäº†å…¼å®¹æ€§ï¼Œè®¾ç½®æ—§çš„æ¥å£å±æ€§
            self._setup_compatibility_attributes()
            
            # åŠ è½½æ¨ç†æ•°æ®ï¼ˆå¯èƒ½éœ€è¦è½¬æ¢ç»´åº¦ï¼‰
            self._load_inference_data()
            
            logger.info("âœ… æ–°çš„åˆ†å±‚Transformeræ¨¡å‹åŠ è½½å®Œæˆ")
            logger.info(f"   æ¨¡å‹: {self.new_model_info['model_name']} v{self.new_model_info['model_version']}")
            logger.info(f"   äºŒåˆ†ç±»å‡†ç¡®ç‡: {self.new_model_info['performance']['binary_stage']['accuracy']:.4f}")
            logger.info(f"   å¤šåˆ†ç±»å‡†ç¡®ç‡: {self.new_model_info['performance']['multi_stage']['accuracy']:.4f}")
            
        except Exception as e:
            logger.error(f"âŒ åˆ†å±‚Transformeræ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def _setup_compatibility_attributes(self):
        """è®¾ç½®å…¼å®¹æ€§å±æ€§ä»¥ä¿æŒç°æœ‰æ¥å£"""
        # æ„é€ å…¼å®¹çš„model_info
        self.model_info = {
            'classes': (['Benign'] + self.new_model_info['classes']['multi']),  # 7ç±»ç³»ç»Ÿ
            'num_classes': 7,
            'model_name': self.new_model_info['model_name'],
            'architecture': 'HierarchicalTransformer'
        }
        
        # æ„é€ å…¼å®¹çš„selected_featuresï¼ˆä½¿ç”¨æ–°æ¨¡å‹çš„77ä¸ªç‰¹å¾ï¼‰
        self.selected_features = self.new_model_info['features']['feature_names']
        
        logger.info(f"âœ… è®¾ç½®å…¼å®¹æ€§æ¥å£: {len(self.model_info['classes'])}ç±»ç³»ç»Ÿ")
        logger.info(f"   å¨èƒç±»åˆ«: {', '.join(self.model_info['classes'])}")
    
    def _load_pytorch_model(self):
        """åŠ è½½PyTorchæ¨¡å‹å¹¶éªŒè¯æƒé‡åŠ è½½"""
        model_path = AI_MODEL_CONFIG['model_file']
        if not model_path.exists():
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        
        # åŠ è½½æ¨¡å‹æ•°æ®
        model_data = torch.load(model_path, map_location='cpu')
        
        if isinstance(model_data, dict) and 'model_state_dict' in model_data:
            # é‡å»ºçœŸå®çš„Ensemble_Hybridæ¨¡å‹
            input_dim = model_data.get('input_dim', 64)
            num_classes = model_data.get('num_classes', 12)
            
            logger.info(f"æ­£åœ¨åˆ›å»ºæ¨¡å‹: input_dim={input_dim}, num_classes={num_classes}")
            self.model = self._create_ensemble_hybrid_model(input_dim, num_classes)
            
            # è®¡ç®—æ¨¡å‹å‚æ•°æ•°é‡
            model_params = sum(p.numel() for p in self.model.parameters())
            logger.info(f"æ¨¡å‹å‚æ•°æ•°é‡: {model_params:,}")
            
            # åŠ è½½çœŸå®æƒé‡
            try:
                self.model.load_state_dict(model_data['model_state_dict'], strict=True)
                logger.info("âœ… æˆåŠŸåŠ è½½çœŸå®æ¨¡å‹æƒé‡")
                
                # éªŒè¯æƒé‡åŠ è½½æˆåŠŸ
                self._verify_model_weights()
                
            except Exception as e:
                logger.error(f"âŒ æƒé‡åŠ è½½å¤±è´¥: {e}")
                logger.error("è¿™å°†å¯¼è‡´æ¨¡å‹ä½¿ç”¨éšæœºæƒé‡ï¼Œé¢„æµ‹ç»“æœä¸å‡†ç¡®ï¼")
                raise RuntimeError(f"æ¨¡å‹æƒé‡åŠ è½½å¤±è´¥: {e}")
        else:
            # ç›´æ¥æ˜¯æ¨¡å‹å¯¹è±¡
            self.model = model_data
        
        self.model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        
        logger.info(f"âœ… PyTorchæ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
    
    def _create_ensemble_hybrid_model(self, input_dim: int, num_classes: int):
        """åˆ›å»ºçœŸå®çš„Ensemble_Hybridæ¨¡å‹æ¶æ„ï¼ˆå®Œå…¨åŒ¹é…training.ipynbï¼‰"""
        import torch.nn as nn
        import torch.nn.functional as F
        
        class ResidualBlock(nn.Module):
            """æ®‹å·®å— - æ”¹å–„æ¢¯åº¦æµåŠ¨"""
            def __init__(self, dim, dropout_rate=0.2):
                super().__init__()
                self.block = nn.Sequential(
                    nn.Linear(dim, dim),
                    nn.BatchNorm1d(dim),
                    nn.ReLU(),
                    nn.Dropout(dropout_rate),
                    nn.Linear(dim, dim),
                    nn.BatchNorm1d(dim)
                )
                self.dropout = nn.Dropout(dropout_rate)
                
            def forward(self, x):
                residual = x
                out = self.block(x)
                out = out + residual
                return F.relu(self.dropout(out))
        
        class SelfAttentionBranch(nn.Module):
            """è‡ªæ³¨æ„åŠ›åˆ†æ”¯"""
            def __init__(self, input_dim, num_classes, dropout_rate=0.2):
                super().__init__()
                self.attention_dim = min(64, input_dim)
                self.query = nn.Linear(input_dim, self.attention_dim)
                self.key = nn.Linear(input_dim, self.attention_dim)
                self.value = nn.Linear(input_dim, self.attention_dim)
                self.output_projection = nn.Linear(self.attention_dim, input_dim)
                self.classifier = nn.Sequential(
                    nn.Linear(input_dim, 128),
                    nn.BatchNorm1d(128),
                    nn.ReLU(),
                    nn.Dropout(dropout_rate),
                    nn.Linear(128, num_classes)
                )
                self._init_weights()
            
            def _init_weights(self):
                for module in self.modules():
                    if isinstance(module, nn.Linear):
                        nn.init.xavier_uniform_(module.weight)
                        if module.bias is not None:
                            nn.init.constant_(module.bias, 0)
            
            def forward(self, x):
                q = self.query(x)
                k = self.key(x)
                v = self.value(x)
                attention_scores = torch.sum(q * k, dim=1, keepdim=True)
                attention_weights = torch.sigmoid(attention_scores)
                attention_weights = torch.clamp(attention_weights, min=1e-8, max=1.0)
                attended = attention_weights * v
                projected = self.output_projection(attended)
                return self.classifier(projected)
        
        class FeatureInteractionBranch(nn.Module):
            """ç‰¹å¾µäº¤äº’åˆ†æ”¯"""
            def __init__(self, input_dim, num_classes, dropout_rate=0.2):
                super().__init__()
                self.interaction_dim = min(8, input_dim // 8)
                self.feature_embeddings = nn.Linear(input_dim, self.interaction_dim)
                self.interaction_output_dim = (self.interaction_dim * (self.interaction_dim - 1)) // 2
                if self.interaction_output_dim == 0:
                    self.interaction_output_dim = 1
                self.classifier = nn.Sequential(
                    nn.Linear(input_dim + self.interaction_output_dim, 128),
                    nn.BatchNorm1d(128),
                    nn.ReLU(),
                    nn.Dropout(dropout_rate),
                    nn.Linear(128, num_classes)
                )
                self._init_weights()
            
            def _init_weights(self):
                for module in self.modules():
                    if isinstance(module, nn.Linear):
                        nn.init.xavier_uniform_(module.weight)
                        if module.bias is not None:
                            nn.init.constant_(module.bias, 0)
            
            def forward(self, x):
                embeddings = torch.tanh(self.feature_embeddings(x))
                interactions = []
                if self.interaction_dim > 1:
                    for i in range(self.interaction_dim):
                        for j in range(i + 1, self.interaction_dim):
                            interaction = embeddings[:, i] * embeddings[:, j]
                            interactions.append(interaction.unsqueeze(1))
                
                if interactions:
                    interaction_features = torch.cat(interactions, dim=1)
                else:
                    interaction_features = torch.zeros(x.size(0), 1, device=x.device)
                
                combined_features = torch.cat([x, interaction_features], dim=1)
                return self.classifier(combined_features)
        
        class Ensemble_Hybrid(nn.Module):
            """é›†æˆæ··åˆç¶²çµ¡ - å®Œå…¨åŒ¹é…training.ipynb"""
            def __init__(self, input_dim, num_classes=12, dropout_rate=0.2):
                super().__init__()
                self.input_dim = input_dim
                self.num_classes = num_classes
                
                self.deep_branch = nn.Sequential(
                    nn.Linear(input_dim, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(dropout_rate),
                    nn.Linear(256, 128), nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(dropout_rate),
                    nn.Linear(128, num_classes)
                )
                self.wide_branch = nn.Sequential(
                    nn.Linear(input_dim, 512), nn.BatchNorm1d(512), nn.ReLU(), nn.Dropout(dropout_rate),
                    nn.Linear(512, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(dropout_rate),
                    nn.Linear(256, num_classes)
                )
                self.res_branch = nn.Sequential(
                    nn.Linear(input_dim, 128), nn.BatchNorm1d(128), nn.ReLU(),
                    ResidualBlock(128, dropout_rate),
                    ResidualBlock(128, dropout_rate),
                    nn.Linear(128, num_classes)
                )
                self.attention_branch = SelfAttentionBranch(input_dim, num_classes, dropout_rate)
                self.interaction_branch = FeatureInteractionBranch(input_dim, num_classes, dropout_rate)
                
                self.weight_net = nn.Sequential(
                    nn.Linear(input_dim, 32), nn.ReLU(), nn.Dropout(dropout_rate),
                    nn.Linear(32, 5), nn.Softmax(dim=1)
                )
                self.final_fusion = nn.Sequential(
                    nn.Linear(num_classes * 5, 128), nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(dropout_rate),
                    nn.Linear(128, num_classes)
                )
                self.global_weights = nn.Parameter(torch.ones(5) / 5)
                self._init_weights()
            
            def _init_weights(self):
                for module in self.modules():
                    if isinstance(module, nn.Linear):
                        nn.init.xavier_uniform_(module.weight)
                        if module.bias is not None: nn.init.constant_(module.bias, 0)
                    elif isinstance(module, nn.BatchNorm1d):
                        nn.init.constant_(module.weight, 1)
                        nn.init.constant_(module.bias, 0)
            
            def forward(self, x, return_intermediate=False):
                if torch.isnan(x).any() or torch.isinf(x).any():
                    x = torch.nan_to_num(x, nan=0.0, posinf=1.0, neginf=-1.0)
                
                outputs = [
                    self.deep_branch(x), self.wide_branch(x), self.res_branch(x),
                    self.attention_branch(x), self.interaction_branch(x)
                ]
                
                for i, out in enumerate(outputs):
                    if torch.isnan(out).any() or torch.isinf(out).any():
                        outputs[i] = torch.nan_to_num(out, nan=0.0, posinf=1.0, neginf=-1.0)
                
                deep_out, wide_out, res_out, att_out, inter_out = outputs
                
                adaptive_weights = torch.clamp(self.weight_net(x), min=1e-8, max=1.0)
                global_weights = torch.clamp(F.softmax(self.global_weights, dim=0), min=1e-8, max=1.0)
                
                outputs_stack = torch.stack(outputs, dim=2)
                
                weighted_output_adaptive = torch.sum(outputs_stack * adaptive_weights.unsqueeze(1), dim=2)
                weighted_output_global = torch.sum(outputs_stack * global_weights.unsqueeze(0).unsqueeze(0), dim=2)
                weighted_output = 0.6 * weighted_output_adaptive + 0.4 * weighted_output_global
                
                concatenated = torch.cat(outputs, dim=1)
                final_output = self.final_fusion(concatenated)
                
                ensemble_output = 0.7 * final_output + 0.3 * weighted_output
                
                if torch.isnan(ensemble_output).any() or torch.isinf(ensemble_output).any():
                    ensemble_output = torch.nan_to_num(ensemble_output, nan=0.0, posinf=1.0, neginf=-1.0)
                    
                if return_intermediate:
                    return {
                        'ensemble': ensemble_output, 'final_fusion': final_output,
                        'weighted': weighted_output, 'branches': tuple(outputs),
                        'weights': (adaptive_weights, global_weights)
                    }
                return ensemble_output
        
        return Ensemble_Hybrid(input_dim, num_classes)
    
    def _verify_model_weights(self):
        """éªŒè¯æ¨¡å‹æƒé‡æ˜¯å¦æ­£ç¡®åŠ è½½"""
        try:
            # åˆ›å»ºä¸€ä¸ªæµ‹è¯•è¾“å…¥ï¼ˆä½¿ç”¨æ‰¹å¤§å°=2æ¥é˜²æ­¢BatchNormé—®é¢˜ï¼‰
            test_input = torch.randn(2, 64)  # æ¨¡æ‹Ÿ64ä¸ªç‰¹å¾çš„è¾“å…¥ï¼Œæ‰¹å¤§å°=2
            
            with torch.no_grad():
                # æ‰§è¡Œå‰å‘ä¼ æ’­
                output = self.model(test_input)
                
                # æ£€æŸ¥è¾“å‡ºæ˜¯å¦åˆç†
                if torch.isnan(output).any() or torch.isinf(output).any():
                    logger.error("æ¨¡å‹è¾“å‡ºåŒ…å«NaNæˆ–Infå€¼")
                    return False
                
                # æ£€æŸ¥è¾“å‡ºç»´åº¦
                if output.shape != (2, 12):
                    logger.error(f"æ¨¡å‹è¾“å‡ºç»´åº¦ä¸æ­£ç¡®: {output.shape}, æœŸæœ›: (2, 12)")
                    return False
                
                # æ£€æŸ¥è¾“å‡ºæ˜¯å¦ä¸ºå…¨é›¶æˆ–å…¨ç›¸åŒå€¼ï¼ˆéšæœºæƒé‡çš„ç‰¹å¾ï¼‰
                if torch.allclose(output, torch.zeros_like(output), atol=1e-6):
                    logger.warning("æ¨¡å‹è¾“å‡ºå…¨ä¸ºé›¶ï¼Œå¯èƒ½æƒé‡åŠ è½½å¤±è´¥")
                    return False
                
                # æ£€æŸ¥è¾“å‡ºæ˜¯å¦å…·æœ‰åˆç†çš„å˜åŒ–èŒƒå›´
                output_std = torch.std(output)
                if output_std < 1e-6:
                    logger.warning(f"æ¨¡å‹è¾“å‡ºæ–¹å·®è¿‡å°: {output_std}, å¯èƒ½æƒé‡åŠ è½½å¤±è´¥")
                    return False
                
                # æ£€æŸ¥ä¸¤ä¸ªæ ·æœ¬çš„è¾“å‡ºæ˜¯å¦ä¸åŒï¼ˆé¿å…å›ºå®šè¾“å‡ºï¼‰
                if torch.allclose(output[0], output[1], atol=1e-4):
                    logger.warning("æ¨¡å‹è¾“å‡ºå›ºå®šä¸å˜ï¼Œå¯èƒ½æƒé‡åŠ è½½å¤±è´¥")
                    return False
                
                logger.info(f"âœ… æ¨¡å‹æƒé‡éªŒè¯æˆåŠŸ: è¾“å‡ºç»´åº¦={output.shape}, æ–¹å·®={output_std:.6f}")
                return True
                
        except Exception as e:
            logger.error(f"æ¨¡å‹æƒé‡éªŒè¯å¤±è´¥: {e}")
            return False
    
    def _load_preprocessors(self):
        """åŠ è½½é¢„å¤„ç†å™¨"""
        self._load_real_preprocessors()
    
    def _load_real_preprocessors(self):
        """åŠ è½½çœŸå®çš„é¢„å¤„ç†å™¨"""
        # æ ¹æ®Context7æ–‡æ¡£ï¼Œä½¿ç”¨joblibæ˜¯scikit-learnæ¨èçš„åºåˆ—åŒ–æ–¹æ³•
        import joblib
        import warnings
        from sklearn.exceptions import InconsistentVersionWarning
        
        # è®¾ç½®warningè¿‡æ»¤å™¨ä»¥ä¾¿å¤„ç†ç‰ˆæœ¬ä¸åŒ¹é…
        warnings.filterwarnings("ignore", category=InconsistentVersionWarning)
        
        # åŠ è½½StandardScaler
        scaler_path = AI_MODEL_CONFIG['scaler_file']
        try:
            self.scaler = joblib.load(scaler_path)
            logger.info(f"âœ… ScaleråŠ è½½æˆåŠŸ(joblib): {scaler_path}")
        except Exception as e:
            logger.warning(f"joblibå¤±è´¥ï¼Œå°è¯•pickle: {e}")
            try:
                with open(scaler_path, 'rb') as f:
                    self.scaler = pickle.load(f)
                logger.info(f"âœ… ScaleråŠ è½½æˆåŠŸ(pickle): {scaler_path}")
            except Exception as e2:
                logger.warning(f"pickleå¤±è´¥ï¼Œå°è¯•protocol=4: {e2}")
                with open(scaler_path, 'rb') as f:
                    self.scaler = pickle.load(f, encoding='latin1')
                logger.info(f"âœ… ScaleråŠ è½½æˆåŠŸ(latin1): {scaler_path}")
        
        # åŠ è½½ç‰¹å¾é€‰æ‹©å™¨
        selector_path = AI_MODEL_CONFIG['feature_selector_file']
        try:
            self.feature_selector = joblib.load(selector_path)
            logger.info(f"âœ… FeatureSelectoråŠ è½½æˆåŠŸ(joblib): {selector_path}")
        except Exception as e:
            logger.warning(f"joblibå¤±è´¥ï¼Œå°è¯•pickle: {e}")
            try:
                with open(selector_path, 'rb') as f:
                    self.feature_selector = pickle.load(f)
                logger.info(f"âœ… FeatureSelectoråŠ è½½æˆåŠŸ(pickle): {selector_path}")
            except Exception as e2:
                logger.warning(f"pickleå¤±è´¥ï¼Œå°è¯•latin1: {e2}")
                with open(selector_path, 'rb') as f:
                    self.feature_selector = pickle.load(f, encoding='latin1')
                logger.info(f"âœ… FeatureSelectoråŠ è½½æˆåŠŸ(latin1): {selector_path}")
        
        # åŠ è½½æ ‡ç­¾ç¼–ç å™¨
        encoder_path = AI_MODEL_CONFIG['label_encoder_file']
        try:
            self.label_encoder = joblib.load(encoder_path)
            logger.info(f"âœ… LabelEncoderåŠ è½½æˆåŠŸ(joblib): {encoder_path}")
        except Exception as e:
            logger.warning(f"joblibå¤±è´¥ï¼Œå°è¯•pickle: {e}")
            try:
                with open(encoder_path, 'rb') as f:
                    self.label_encoder = pickle.load(f)
                logger.info(f"âœ… LabelEncoderåŠ è½½æˆåŠŸ(pickle): {encoder_path}")
            except Exception as e2:
                logger.warning(f"pickleå¤±è´¥ï¼Œå°è¯•latin1: {e2}")
                with open(encoder_path, 'rb') as f:
                    self.label_encoder = pickle.load(f, encoding='latin1')
                logger.info(f"âœ… LabelEncoderåŠ è½½æˆåŠŸ(latin1): {encoder_path}")
    
    
    def _load_metadata(self):
        """åŠ è½½æ¨¡å‹å…ƒæ•°æ®"""
        # åŠ è½½æ¨¡å‹ä¿¡æ¯
        info_path = AI_MODEL_CONFIG['model_info_file']
        with open(info_path, 'r') as f:
            self.model_info = json.load(f)
        logger.info(f"âœ… æ¨¡å‹ä¿¡æ¯åŠ è½½æˆåŠŸ: {self.model_info['num_classes']}ä¸ªå¨èƒç±»åˆ«")
        
        # åŠ è½½é€‰æ‹©çš„ç‰¹å¾
        features_path = AI_MODEL_CONFIG['selected_features_file']
        with open(features_path, 'r') as f:
            self.selected_features = json.load(f)
        logger.info(f"âœ… ç‰¹å¾ä¿¡æ¯åŠ è½½æˆåŠŸ: {len(self.selected_features)}ä¸ªç‰¹å¾")
    
    def _load_inference_data(self):
        """åŠ è½½æ¨ç†æµ‹è¯•æ•°æ®"""
        try:
            data_path = AI_MODEL_CONFIG['inference_data_file']
            loaded_data = torch.load(data_path, map_location='cpu')
            
            # æ£€æŸ¥æ•°æ®æ ¼å¼
            if isinstance(loaded_data, dict) and 'features' in loaded_data:
                # æ–°æ ¼å¼ï¼šåŒ…å«features, labels, class_names
                self.inference_data = loaded_data['features']
                self.inference_labels = loaded_data['labels'] 
                self.inference_class_names = loaded_data['class_names']
                logger.info(f"âœ… æ–°æ ¼å¼æ¨ç†æ•°æ®åŠ è½½æˆåŠŸ: {len(self.inference_data)}ä¸ªæ ·æœ¬")
                logger.info(f"   ç±»åˆ«: {', '.join(self.inference_class_names)}")
            else:
                # æ—§æ ¼å¼ï¼šç›´æ¥æ˜¯tensor
                self.inference_data = loaded_data
                self.inference_labels = None
                self.inference_class_names = None
                logger.info(f"âœ… æ—§æ ¼å¼æ¨ç†æ•°æ®åŠ è½½æˆåŠŸ: {len(self.inference_data)}ä¸ªæ ·æœ¬")
                
        except Exception as e:
            logger.error(f"âŒ æ— æ³•åŠ è½½æ¨ç†æ•°æ®: {e}")
            raise RuntimeError(f"æ— æ³•åŠ è½½å¿…éœ€çš„æ¨ç†æ•°æ®æ–‡ä»¶: {data_path}")
    
    
    def _get_true_labels(self) -> List[str]:
        """é‡å»ºçœŸå®æ ‡ç­¾æ˜ å°„ï¼ˆåŸºäºæŠ½æ ·è„šæœ¬çš„shuffleé€»è¾‘ï¼‰"""
        # é‡å»ºæ ‡ç­¾åˆ—è¡¨ï¼ˆä¸æ‰€æœ‰åˆ†æè„šæœ¬ä¸­ä½¿ç”¨çš„é€»è¾‘ä¸€è‡´ï¼‰
        labels = []
        labels.extend(['Benign'] * 120)  # å‰120ä¸ªæ˜¯Benign
        threat_classes = ['Bot', 'DDoS', 'DoS GoldenEye', 'DoS Hulk', 'DoS Slowhttptest', 
                         'DoS slowloris', 'FTP-Patator', 'PortScan', 'Rare_Attack', 'SSH-Patator', 'Web Attack  Brute Force']
        for class_name in threat_classes:  # å…¶ä½™ç±»åˆ«æ¯ä¸ª10ä¸ª
            labels.extend([class_name] * 10)
        
        # ä½¿ç”¨å›ºå®šç§å­åº”ç”¨shuffleï¼ˆä¸æŠ½æ ·è„šæœ¬ä¸€è‡´ï¼‰
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä¿å­˜éšæœºçŠ¶æ€ï¼Œé¿å…æ¯æ¬¡è°ƒç”¨éƒ½é‡ç½®éšæœºç§å­
        random_state = np.random.get_state()
        np.random.seed(42)
        shuffled_indices = np.random.permutation(len(labels))
        shuffled_labels = [labels[i] for i in shuffled_indices]
        np.random.set_state(random_state)  # æ¢å¤éšæœºçŠ¶æ€
        
        return shuffled_labels
    
    def get_random_attack_sample(self) -> Tuple[np.ndarray, str]:
        """éšæœºè·å–ä¸€ä¸ªæ”»å‡»æ ·æœ¬ - ä½¿ç”¨æ–°çš„æ¨ç†æ•°æ®æ ¼å¼"""
        if self.inference_data is None:
            raise RuntimeError("æ¨ç†æ•°æ®æœªåŠ è½½")
        
        if self.inference_labels is not None and self.inference_class_names is not None:
            # æ–°æ ¼å¼æ•°æ®ï¼šä½¿ç”¨çœŸå®æ ‡ç­¾
            # æ‰¾åˆ°æ‰€æœ‰éBenignçš„æ”»å‡»æ ·æœ¬
            attack_indices = []
            for i, label_idx in enumerate(self.inference_labels):
                class_name = self.inference_class_names[label_idx]
                if class_name != 'Benign':
                    attack_indices.append(i)
            
            if not attack_indices:
                raise RuntimeError("æ²¡æœ‰æ‰¾åˆ°æ”»å‡»æ ·æœ¬")
            
            # éšæœºé€‰æ‹©ä¸€ä¸ªæ”»å‡»æ ·æœ¬
            sample_idx = np.random.choice(attack_indices)
            true_label_idx = self.inference_labels[sample_idx].item()
            true_label = self.inference_class_names[true_label_idx]
            
            # æ˜ å°„åˆ°æ–°çš„7ç±»ç³»ç»Ÿ
            label_mapping = {
                'Bot': 'Bot',
                'Brute_Force': 'Brute_Force', 
                'DDoS': 'DDoS',
                'DoS': 'DoS',
                'PortScan': 'PortScan',
                'Web Attack  Brute Force': 'Web_Attack',
                'Web Attack  Sql Injection': 'Web_Attack', 
                'Web Attack  XSS': 'Web_Attack'
            }
            mapped_label = label_mapping.get(true_label, 'Web_Attack')
            
        else:
            # æ—§æ ¼å¼æ•°æ®ï¼šä½¿ç”¨æ—§çš„æ ‡ç­¾é‡å»ºé€»è¾‘
            true_labels = self._get_true_labels_new_system()
            attack_indices = [i for i, label in enumerate(true_labels) if label != 'Benign']
            
            if not attack_indices:
                raise RuntimeError("æ²¡æœ‰æ‰¾åˆ°æ”»å‡»æ ·æœ¬")
            
            sample_idx = np.random.choice(attack_indices)
            mapped_label = true_labels[sample_idx]
        
        # æå–ç‰¹å¾
        features = self.inference_data[sample_idx].numpy()
        
        # ç¡®ä¿featuresæ˜¯1Dæ•°ç»„
        if features.ndim > 1:
            features = features.flatten()
        
        return features, mapped_label
    
    def _get_true_labels_new_system(self) -> List[str]:
        """è·å–çœŸå®æ ‡ç­¾æ˜ å°„ï¼Œè½¬æ¢åˆ°æ–°çš„7ç±»ç³»ç»Ÿ"""
        # åŸæ¥çš„12ç±»æ ‡ç­¾æ˜ å°„
        old_labels = self._get_true_labels()
        
        # 12ç±»åˆ°7ç±»çš„æ˜ å°„å…³ç³»
        label_mapping = {
            'Benign': 'Benign',
            'Bot': 'Bot',
            'DDoS': 'DDoS',
            'DoS GoldenEye': 'DoS',
            'DoS Hulk': 'DoS', 
            'DoS Slowhttptest': 'DoS',
            'DoS slowloris': 'DoS',
            'FTP-Patator': 'Brute_Force',
            'SSH-Patator': 'Brute_Force',
            'PortScan': 'PortScan',
            'Web Attack  Brute Force': 'Web_Attack',
            'Rare_Attack': 'Web_Attack'  # å½’ç±»ä¸ºWebæ”»å‡»
        }
        
        # è½¬æ¢æ ‡ç­¾
        new_labels = [label_mapping.get(label, 'Web_Attack') for label in old_labels]
        return new_labels
    
    def predict_threat(self, features: np.ndarray, is_preprocessed: bool = False, strategy: str = "original") -> Dict:
        """æ‰§è¡Œå¨èƒé¢„æµ‹ - ä½¿ç”¨åˆ†å±‚Transformeræ¨¡å‹"""
        try:
            # æ£€æŸ¥æ•°æ®æ˜¯å¦å·²é¢„å¤„ç†
            if is_preprocessed and features.shape[-1] == 77:
                # æ–°çš„77ç»´å·²é¢„å¤„ç†æ•°æ®ï¼Œç›´æ¥è½¬æ¢ä¸ºtensorï¼Œè·³è¿‡æ¨¡å‹å†…éƒ¨é¢„å¤„ç†
                processed_features = features
                logger.debug("ä½¿ç”¨77ç»´å·²é¢„å¤„ç†æ•°æ®ï¼Œè·³è¿‡æ¨¡å‹é¢„å¤„ç†")
                
                # ç¡®ä¿æ˜¯2Dæ•°ç»„æ ¼å¼
                if processed_features.ndim == 1:
                    processed_features = processed_features.reshape(1, -1)
                    
                logger.debug(f"è¾“å…¥ç‰¹å¾ç»´åº¦: {processed_features.shape}")
                
                # ç›´æ¥è°ƒç”¨æ¨¡å‹ï¼Œè·³è¿‡é¢„å¤„ç†æ­¥éª¤
                import torch
                with torch.no_grad():
                    input_tensor = torch.FloatTensor(processed_features).to(self.transformer_loader.device)
                    
                    # äºŒåˆ†ç±»é¢„æµ‹
                    binary_logits, binary_uncertainty = self.transformer_loader.binary_model(input_tensor, return_uncertainty=True)
                    binary_probs = torch.nn.functional.softmax(binary_logits, dim=1)
                    binary_preds = torch.argmax(binary_probs, dim=1)
                    
                    # å¤šåˆ†ç±»é¢„æµ‹ï¼ˆä»…æ¶æ„æµé‡ï¼‰
                    multi_probs = torch.zeros(len(processed_features), len(self.new_model_info['classes']['multi']))
                    multi_uncertainty = torch.zeros(len(processed_features), 1)
                    
                    malicious_mask = binary_preds == 1
                    if malicious_mask.sum() > 0:
                        malicious_data = input_tensor[malicious_mask]
                        multi_logits, multi_unc = self.transformer_loader.multi_model(malicious_data, return_uncertainty=True)
                        multi_probs[malicious_mask] = torch.nn.functional.softmax(multi_logits, dim=1)
                        multi_uncertainty[malicious_mask] = multi_unc
                    
                    prediction_result = {
                        'binary': {
                            'predictions': binary_preds.cpu().numpy(),
                            'probabilities': binary_probs.cpu().numpy(),
                            'uncertainty': binary_uncertainty.cpu().numpy(),
                            'classes': self.new_model_info['classes']['binary']
                        },
                        'multi': {
                            'probabilities': multi_probs.cpu().numpy(),
                            'uncertainty': multi_uncertainty.cpu().numpy(),
                            'classes': self.new_model_info['classes']['multi']
                        },
                        'metadata': {
                            'model_name': self.new_model_info['model_name'],
                            'num_samples': len(processed_features)
                        }
                    }
            else:
                # æ—§çš„64ç»´æ•°æ®æˆ–éœ€è¦ç»´åº¦é€‚é…çš„æ•°æ®
                processed_features = self._adapt_feature_dimensions(features)
                logger.debug("åº”ç”¨ç»´åº¦é€‚é…å’Œé¢„å¤„ç†")
                
                # ç¡®ä¿æ˜¯2Dæ•°ç»„æ ¼å¼
                if processed_features.ndim == 1:
                    processed_features = processed_features.reshape(1, -1)
                    
                logger.debug(f"è¾“å…¥ç‰¹å¾ç»´åº¦: {processed_features.shape}")
                
                # ä½¿ç”¨æ–°çš„åˆ†å±‚æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼ˆåŒ…å«å†…éƒ¨é¢„å¤„ç†ï¼‰
                prediction_result = self.transformer_loader.predict(processed_features)
            
            # åˆ†å±‚é¢„æµ‹é€»è¾‘
            binary_pred = prediction_result['binary']['predictions'][0]  # 0=Benign, 1=Malicious
            binary_probs = prediction_result['binary']['probabilities'][0]  # [benign_prob, malicious_prob]
            binary_confidence = max(binary_probs)
            
            if binary_pred == 0:  # Benign
                predicted_class = "Benign"
                confidence = binary_probs[0]  # Benignçš„æ¦‚ç‡
                all_probs = [binary_probs[0]] + [0.0] * 6  # Benign + 6ä¸ªæ”»å‡»ç±»å‹éƒ½æ˜¯0
            else:  # Malicious
                # å¤šåˆ†ç±»é˜¶æ®µï¼šè·å–æœ€å¯èƒ½çš„æ”»å‡»ç±»å‹
                multi_probs = prediction_result['multi']['probabilities'][0]  # 6ç±»æ”»å‡»æ¦‚ç‡
                max_attack_idx = np.argmax(multi_probs)
                predicted_class = self.new_model_info['classes']['multi'][max_attack_idx]
                confidence = multi_probs[max_attack_idx] * binary_probs[1]  # ç»„åˆç½®ä¿¡åº¦
                
                # æ„é€ å®Œæ•´æ¦‚ç‡åˆ†å¸ƒ [Benign=0, Attack1, Attack2, ...]
                all_probs = [0.0] + multi_probs.tolist()
            
            # ç¡®å®šå“åº”çº§åˆ«
            response_level = self._determine_response_level(confidence)
            
            logger.debug(f"åˆ†å±‚é¢„æµ‹ç»“æœ: äºŒåˆ†ç±»={binary_pred}, æœ€ç»ˆç±»åˆ«={predicted_class}, ç½®ä¿¡åº¦={confidence:.4f}")
            
            return {
                "predicted_class": predicted_class,
                "confidence": float(confidence),  # è½¬æ¢ä¸ºPython float
                "response_level": response_level,
                "all_probabilities": [float(p) for p in all_probs],  # è½¬æ¢ä¸ºPython floatåˆ—è¡¨
                "class_names": self.model_info['classes'],
                "hierarchical_info": {
                    "binary_prediction": "Malicious" if binary_pred == 1 else "Benign",
                    "binary_confidence": float(binary_confidence),  # è½¬æ¢ä¸ºPython float
                    "attack_type": predicted_class if binary_pred == 1 else None
                }
            }
                
        except Exception as e:
            logger.error(f"âŒ å¨èƒé¢„æµ‹å¤±è´¥: {e}")
            raise
    
    def _adapt_feature_dimensions(self, features: np.ndarray) -> np.ndarray:
        """å°†64ç»´ç‰¹å¾é€‚é…ä¸º77ç»´ç‰¹å¾"""
        if features.shape[-1] == 77:
            return features  # å·²ç»æ˜¯77ç»´
        elif features.shape[-1] == 64:
            # ä»64ç»´æ‰©å±•åˆ°77ç»´ï¼šæ·»åŠ 13ä¸ªé›¶å€¼ç‰¹å¾
            if features.ndim == 1:
                padding = np.zeros(13)
                return np.concatenate([features, padding])
            else:
                padding = np.zeros((features.shape[0], 13))
                return np.concatenate([features, padding], axis=1)
        else:
            # å…¶ä»–ç»´åº¦ï¼šæˆªæ–­æˆ–å¡«å……åˆ°77ç»´
            target_dim = 77
            if features.ndim == 1:
                if features.shape[0] > target_dim:
                    return features[:target_dim]
                else:
                    padding = np.zeros(target_dim - features.shape[0])
                    return np.concatenate([features, padding])
            else:
                if features.shape[1] > target_dim:
                    return features[:, :target_dim]
                else:
                    padding = np.zeros((features.shape[0], target_dim - features.shape[1]))
                    return np.concatenate([features, padding], axis=1)
    
    def _preprocess_features(self, features: np.ndarray) -> np.ndarray:
        """é¢„å¤„ç†ç‰¹å¾æ•°æ® - ä¿®å¤ç»´åº¦ä¸åŒ¹é…é—®é¢˜"""
        # ç¡®ä¿è¾“å…¥æ˜¯2Dæ•°ç»„
        if features.ndim == 1:
            features = features.reshape(1, -1)
        
        logger.debug(f"åŸå§‹ç‰¹å¾ç»´åº¦: {features.shape}")
        
        # æ£€æŸ¥ç‰¹å¾é€‰æ‹©å™¨çš„æœŸæœ›è¾“å…¥ç»´åº¦
        expected_features_for_selector = getattr(self.feature_selector, 'n_features_in_', 65)
        
        # å…³é”®ä¿®å¤ï¼šå¦‚æœæˆ‘ä»¬çš„æ•°æ®åªæœ‰64ç»´ï¼Œä½†ç‰¹å¾é€‰æ‹©å™¨æœŸæœ›65ç»´è¾“å…¥
        if features.shape[1] == 64 and expected_features_for_selector == 65:
            # æ·»åŠ ä¸€ä¸ªé¢å¤–ç‰¹å¾ï¼ˆä½¿ç”¨å‡å€¼æˆ–é›¶å€¼ï¼‰
            # è¿™é‡Œä½¿ç”¨é›¶å€¼ï¼Œå› ä¸ºå®ƒä¸ä¼šå½±å“ç‰¹å¾é€‰æ‹©çš„ç»“æœ
            extra_feature = np.zeros((features.shape[0], 1))
            features = np.concatenate([features, extra_feature], axis=1)
            logger.info(f"æ·»åŠ ä¸€ä¸ªé›¶å€¼ç‰¹å¾ä»¥åŒ¹é…ç‰¹å¾é€‰æ‹©å™¨: {features.shape}")
        
        # å…¶ä»–ç»´åº¦ä¸åŒ¹é…æƒ…å†µçš„å¤„ç†
        elif features.shape[1] != expected_features_for_selector:
            logger.warning(f"ç‰¹å¾ç»´åº¦ä¸åŒ¹é…: å®é™…{features.shape[1]}, ç‰¹å¾é€‰æ‹©å™¨æœŸæœ›{expected_features_for_selector}")
            
            if features.shape[1] < expected_features_for_selector:
                # å¦‚æœç‰¹å¾ä¸è¶³ï¼Œç”¨é›¶å€¼å¡«å……
                padding = np.zeros((features.shape[0], expected_features_for_selector - features.shape[1]))
                features = np.concatenate([features, padding], axis=1)
                logger.info(f"ç‰¹å¾å¡«å……åˆ°{expected_features_for_selector}ç»´: {features.shape}")
            elif features.shape[1] > expected_features_for_selector:
                # å¦‚æœç‰¹å¾è¿‡å¤šï¼Œæˆªå–å‰Nä¸ª
                features = features[:, :expected_features_for_selector]
                logger.info(f"ç‰¹å¾æˆªå–åˆ°{expected_features_for_selector}ç»´: {features.shape}")
        
        # æ­¥éª¤1: ç‰¹å¾é€‰æ‹©ï¼ˆä»65ç»´é€‰æ‹©64ç»´ï¼‰
        try:
            selected_features = self.feature_selector.transform(features)
            logger.debug(f"ç‰¹å¾é€‰æ‹©åç»´åº¦: {selected_features.shape}")
        except Exception as e:
            logger.warning(f"ç‰¹å¾é€‰æ‹©å¤±è´¥: {e}ï¼Œæ‰‹åŠ¨é€‰æ‹©å‰64ä¸ªç‰¹å¾")
            n_select = min(64, features.shape[1])
            selected_features = features[:, :n_select]
        
        # æ­¥éª¤2: æ ‡å‡†åŒ–ï¼ˆå¯¹64ç»´ç‰¹å¾è¿›è¡Œæ ‡å‡†åŒ–ï¼‰
        try:
            scaled_features = self.scaler.transform(selected_features)
            logger.debug(f"æ ‡å‡†åŒ–åç»´åº¦: {scaled_features.shape}")
        except Exception as e:
            logger.warning(f"Scalerå˜æ¢å¤±è´¥: {e}ï¼Œä½¿ç”¨æœªæ ‡å‡†åŒ–ç‰¹å¾")
            scaled_features = selected_features
        
        return scaled_features.flatten()
    
    def _apply_improved_decision_strategy(self, probabilities: torch.Tensor, strategy: str = "original") -> tuple:
        """åº”ç”¨æ”¹è¿›çš„å†³ç­–ç­–ç•¥æ¥æé«˜æ”»å‡»æ£€æµ‹å‡†ç¡®ç‡"""
        # è·å–æ‰€æœ‰ç±»åˆ«åç§°
        class_names = self.model_info['classes']
        
        # æŒ‰æ¦‚ç‡æ’åº
        sorted_indices = torch.argsort(probabilities, descending=True)
        
        # è·å–Benignç±»åˆ«çš„ç´¢å¼•å’Œæ¦‚ç‡
        benign_idx = class_names.index('Benign')
        benign_prob = probabilities[benign_idx].item()
        
        if strategy == "original":
            # ç­–ç•¥2ï¼šç›´æ¥ä½¿ç”¨æ¨¡å‹çš„åŸå§‹é¢„æµ‹ç»“æœ
            predicted_class_idx = sorted_indices[0].item()
            confidence = probabilities[predicted_class_idx].item()
            predicted_class = self.label_encoder.inverse_transform([predicted_class_idx])[0]
            return predicted_class_idx, confidence, predicted_class
            
        elif strategy == "attack_vs_benign":
            # ç­–ç•¥3ï¼šæ¯”è¾ƒæ”»å‡»ç±»åˆ«æ€»æ¦‚ç‡ vs Benignæ¦‚ç‡
            # è®¡ç®—æ‰€æœ‰æ”»å‡»ç±»åˆ«çš„æ¦‚ç‡æ€»å’Œ
            attack_prob_sum = 0.0
            for i, class_name in enumerate(class_names):
                if class_name != 'Benign':
                    attack_prob_sum += probabilities[i].item()
            
            if attack_prob_sum > benign_prob:
                # æ”»å‡»æ¦‚ç‡æ€»å’Œæ›´é«˜ï¼Œé€‰æ‹©æ¦‚ç‡æœ€é«˜çš„æ”»å‡»ç±»åˆ«
                for idx in sorted_indices:
                    if class_names[idx] != 'Benign':
                        predicted_class_idx = idx.item()
                        confidence = probabilities[predicted_class_idx].item()
                        predicted_class = self.label_encoder.inverse_transform([predicted_class_idx])[0]
                        return predicted_class_idx, confidence, predicted_class
            else:
                # Benignæ¦‚ç‡æ›´é«˜ï¼Œé€‰æ‹©Benign
                predicted_class_idx = benign_idx
                confidence = benign_prob
                predicted_class = 'Benign'
                return predicted_class_idx, confidence, predicted_class
        
        else:
            # é»˜è®¤ä½¿ç”¨åŸå§‹ç­–ç•¥
            predicted_class_idx = sorted_indices[0].item()
            confidence = probabilities[predicted_class_idx].item()
            predicted_class = self.label_encoder.inverse_transform([predicted_class_idx])[0]
            return predicted_class_idx, confidence, predicted_class
    
    def _determine_response_level(self, confidence: float) -> str:
        """æ ¹æ®ç½®ä¿¡åº¦ç¡®å®šå“åº”çº§åˆ«"""
        if confidence > THREAT_THRESHOLDS['high_confidence']:
            return "automatic_response"
        elif confidence > THREAT_THRESHOLDS['medium_high']:
            return "auto_create_proposal"
        elif confidence > THREAT_THRESHOLDS['medium_low']:
            return "manual_decision_alert"
        else:
            return "silent_logging"
    
    def simulate_attack_detection(self) -> Dict:
        """æ¨¡æ‹Ÿæ”»å‡»æ£€æµ‹å®Œæ•´æµç¨‹"""
        try:
            # è·å–éšæœºæ”»å‡»æ ·æœ¬
            features, true_label = self.get_random_attack_sample()
            
            # æ‰§è¡Œé¢„æµ‹ï¼ˆinference_dataä¸­çš„æ•°æ®å·²é¢„å¤„ç†ï¼‰
            prediction_result = self.predict_threat(features, is_preprocessed=True)
            
            # æ·»åŠ çœŸå®æ ‡ç­¾ä¿¡æ¯
            prediction_result['true_label'] = true_label
            prediction_result['sample_features'] = features.tolist()
            
            logger.info(f"ğŸ¯ æ¨¡æ‹Ÿæ”»å‡»æ£€æµ‹å®Œæˆ:")
            logger.info(f"   çœŸå®æ ‡ç­¾: {true_label}")
            logger.info(f"   é¢„æµ‹ç±»åˆ«: {prediction_result['predicted_class']}")
            logger.info(f"   ç½®ä¿¡åº¦: {prediction_result['confidence']:.4f}")
            logger.info(f"   å“åº”çº§åˆ«: {prediction_result['response_level']}")
            
            return prediction_result
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡æ‹Ÿæ”»å‡»æ£€æµ‹å¤±è´¥: {e}")
            raise
    
    def get_model_info(self) -> Dict:
        """è·å–æ¨¡å‹ä¿¡æ¯ - è¿”å›æ–°çš„7ç±»ç³»ç»Ÿä¿¡æ¯"""
        # å¤„ç† inference_data çš„é•¿åº¦è®¡ç®—
        inference_samples = 0
        if self.inference_data is not None:
            if hasattr(self.inference_data, 'shape'):
                # å¦‚æœæ˜¯ tensorï¼Œä½¿ç”¨ shape[0]
                inference_samples = self.inference_data.shape[0]
            elif hasattr(self.inference_data, '__len__'):
                # å¦‚æœæ˜¯åˆ—è¡¨æˆ–å…¶ä»–å¯è¿­ä»£å¯¹è±¡
                inference_samples = len(self.inference_data)
        
        return {
            "model_info": self.model_info,
            "feature_count": len(self.selected_features) if self.selected_features else 0,
            "threat_classes": self.model_info['classes'] if self.model_info else [],
            "thresholds": THREAT_THRESHOLDS,
            "inference_samples": inference_samples,
            "new_model_details": {
                "architecture": "HierarchicalTransformer",
                "binary_accuracy": self.new_model_info['performance']['binary_stage']['accuracy'],
                "multi_accuracy": self.new_model_info['performance']['multi_stage']['accuracy'],
                "input_features": self.new_model_info['architecture']['input_features'],
                "hierarchical_classes": {
                    "binary": self.new_model_info['classes']['binary'],
                    "multi": self.new_model_info['classes']['multi']
                }
            }
        }

# å…¨å±€æ¨¡å‹å®ä¾‹
threat_model = None

def get_threat_model() -> ThreatDetectionModel:
    """è·å–å¨èƒæ£€æµ‹æ¨¡å‹å•ä¾‹"""
    global threat_model
    if threat_model is None:
        threat_model = ThreatDetectionModel()
    return threat_model

def init_threat_model():
    """åˆå§‹åŒ–å¨èƒæ£€æµ‹æ¨¡å‹"""
    global threat_model
    threat_model = ThreatDetectionModel()
    return threat_model