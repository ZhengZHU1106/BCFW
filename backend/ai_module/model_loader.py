"""
AIæ¨¡å‹åŠ è½½å’Œæ¨ç†æ¨¡å—
"""

import torch
import pickle
import json
import numpy as np
from pathlib import Path
import logging
from typing import Dict, List, Tuple, Optional
from ..config import AI_MODEL_CONFIG, THREAT_THRESHOLDS

logger = logging.getLogger(__name__)

class ThreatDetectionModel:
    """å¨èƒæ£€æµ‹æ¨¡å‹ç®¡ç†å™¨"""
    
    def __init__(self):
        self.model = None
        self.scaler = None
        self.feature_selector = None
        self.label_encoder = None
        self.model_info = None
        self.selected_features = None
        self.inference_data = None
        self._load_all_components()
    
    def _load_all_components(self):
        """åŠ è½½æ‰€æœ‰æ¨¡å‹ç»„ä»¶"""
        try:
            logger.info("ğŸ¤– å¼€å§‹åŠ è½½AIæ¨¡å‹ç»„ä»¶...")
            
            # åŠ è½½é¢„å¤„ç†ç»„ä»¶å…ˆï¼ˆéœ€è¦ç”¨äºæ¨¡å‹éªŒè¯ï¼‰
            self._load_preprocessors()
            
            # åŠ è½½æ¨¡å‹ä¿¡æ¯å’Œç‰¹å¾
            self._load_metadata()
            
            # åŠ è½½PyTorchæ¨¡å‹ï¼ˆæœ€ååŠ è½½ï¼Œå› ä¸ºéœ€è¦éªŒè¯ï¼‰
            self._load_pytorch_model()
            
            # åŠ è½½æ¨ç†æ•°æ®
            self._load_inference_data()
            
            logger.info("âœ… AIæ¨¡å‹ç»„ä»¶åŠ è½½å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ AIæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def _load_pytorch_model(self):
        """åŠ è½½PyTorchæ¨¡å‹å¹¶éªŒè¯æƒé‡åŠ è½½"""
        model_path = AI_MODEL_CONFIG['model_file']
        if not model_path.exists():
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        
        # åŠ è½½æ¨¡å‹æ•°æ®
        model_data = torch.load(model_path, map_location='cpu')
        
        if isinstance(model_data, dict) and 'model_state_dict' in model_data:
            # é‡å»ºçœŸå®çš„Ensemble_Hybridæ¨¡å‹
            input_dim = model_data.get('input_dim', 64)
            num_classes = model_data.get('num_classes', 12)
            
            logger.info(f"æ­£åœ¨åˆ›å»ºæ¨¡å‹: input_dim={input_dim}, num_classes={num_classes}")
            self.model = self._create_ensemble_hybrid_model(input_dim, num_classes)
            
            # è®¡ç®—æ¨¡å‹å‚æ•°æ•°é‡
            model_params = sum(p.numel() for p in self.model.parameters())
            logger.info(f"æ¨¡å‹å‚æ•°æ•°é‡: {model_params:,}")
            
            # åŠ è½½çœŸå®æƒé‡
            try:
                self.model.load_state_dict(model_data['model_state_dict'], strict=True)
                logger.info("âœ… æˆåŠŸåŠ è½½çœŸå®æ¨¡å‹æƒé‡")
                
                # éªŒè¯æƒé‡åŠ è½½æˆåŠŸ
                self._verify_model_weights()
                
            except Exception as e:
                logger.error(f"âŒ æƒé‡åŠ è½½å¤±è´¥: {e}")
                logger.error("è¿™å°†å¯¼è‡´æ¨¡å‹ä½¿ç”¨éšæœºæƒé‡ï¼Œé¢„æµ‹ç»“æœä¸å‡†ç¡®ï¼")
                raise RuntimeError(f"æ¨¡å‹æƒé‡åŠ è½½å¤±è´¥: {e}")
        else:
            # ç›´æ¥æ˜¯æ¨¡å‹å¯¹è±¡
            self.model = model_data
        
        self.model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        
        logger.info(f"âœ… PyTorchæ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
    
    def _create_ensemble_hybrid_model(self, input_dim: int, num_classes: int):
        """åˆ›å»ºçœŸå®çš„Ensemble_Hybridæ¨¡å‹æ¶æ„ï¼ˆå®Œå…¨åŒ¹é…training.ipynbï¼‰"""
        import torch.nn as nn
        import torch.nn.functional as F
        
        class ResidualBlock(nn.Module):
            """æ®‹å·®å— - æ”¹å–„æ¢¯åº¦æµåŠ¨"""
            def __init__(self, dim, dropout_rate=0.2):
                super().__init__()
                self.block = nn.Sequential(
                    nn.Linear(dim, dim),
                    nn.BatchNorm1d(dim),
                    nn.ReLU(),
                    nn.Dropout(dropout_rate),
                    nn.Linear(dim, dim),
                    nn.BatchNorm1d(dim)
                )
                self.dropout = nn.Dropout(dropout_rate)
                
            def forward(self, x):
                residual = x
                out = self.block(x)
                out = out + residual
                return F.relu(self.dropout(out))
        
        class SelfAttentionBranch(nn.Module):
            """è‡ªæ³¨æ„åŠ›åˆ†æ”¯"""
            def __init__(self, input_dim, num_classes, dropout_rate=0.2):
                super().__init__()
                self.attention_dim = min(64, input_dim)
                self.query = nn.Linear(input_dim, self.attention_dim)
                self.key = nn.Linear(input_dim, self.attention_dim)
                self.value = nn.Linear(input_dim, self.attention_dim)
                self.output_projection = nn.Linear(self.attention_dim, input_dim)
                self.classifier = nn.Sequential(
                    nn.Linear(input_dim, 128),
                    nn.BatchNorm1d(128),
                    nn.ReLU(),
                    nn.Dropout(dropout_rate),
                    nn.Linear(128, num_classes)
                )
                self._init_weights()
            
            def _init_weights(self):
                for module in self.modules():
                    if isinstance(module, nn.Linear):
                        nn.init.xavier_uniform_(module.weight)
                        if module.bias is not None:
                            nn.init.constant_(module.bias, 0)
            
            def forward(self, x):
                q = self.query(x)
                k = self.key(x)
                v = self.value(x)
                attention_scores = torch.sum(q * k, dim=1, keepdim=True)
                attention_weights = torch.sigmoid(attention_scores)
                attention_weights = torch.clamp(attention_weights, min=1e-8, max=1.0)
                attended = attention_weights * v
                projected = self.output_projection(attended)
                return self.classifier(projected)
        
        class FeatureInteractionBranch(nn.Module):
            """ç‰¹å¾µäº¤äº’åˆ†æ”¯"""
            def __init__(self, input_dim, num_classes, dropout_rate=0.2):
                super().__init__()
                self.interaction_dim = min(8, input_dim // 8)
                self.feature_embeddings = nn.Linear(input_dim, self.interaction_dim)
                self.interaction_output_dim = (self.interaction_dim * (self.interaction_dim - 1)) // 2
                if self.interaction_output_dim == 0:
                    self.interaction_output_dim = 1
                self.classifier = nn.Sequential(
                    nn.Linear(input_dim + self.interaction_output_dim, 128),
                    nn.BatchNorm1d(128),
                    nn.ReLU(),
                    nn.Dropout(dropout_rate),
                    nn.Linear(128, num_classes)
                )
                self._init_weights()
            
            def _init_weights(self):
                for module in self.modules():
                    if isinstance(module, nn.Linear):
                        nn.init.xavier_uniform_(module.weight)
                        if module.bias is not None:
                            nn.init.constant_(module.bias, 0)
            
            def forward(self, x):
                embeddings = torch.tanh(self.feature_embeddings(x))
                interactions = []
                if self.interaction_dim > 1:
                    for i in range(self.interaction_dim):
                        for j in range(i + 1, self.interaction_dim):
                            interaction = embeddings[:, i] * embeddings[:, j]
                            interactions.append(interaction.unsqueeze(1))
                
                if interactions:
                    interaction_features = torch.cat(interactions, dim=1)
                else:
                    interaction_features = torch.zeros(x.size(0), 1, device=x.device)
                
                combined_features = torch.cat([x, interaction_features], dim=1)
                return self.classifier(combined_features)
        
        class Ensemble_Hybrid(nn.Module):
            """é›†æˆæ··åˆç¶²çµ¡ - å®Œå…¨åŒ¹é…training.ipynb"""
            def __init__(self, input_dim, num_classes=12, dropout_rate=0.2):
                super().__init__()
                self.input_dim = input_dim
                self.num_classes = num_classes
                
                self.deep_branch = nn.Sequential(
                    nn.Linear(input_dim, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(dropout_rate),
                    nn.Linear(256, 128), nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(dropout_rate),
                    nn.Linear(128, num_classes)
                )
                self.wide_branch = nn.Sequential(
                    nn.Linear(input_dim, 512), nn.BatchNorm1d(512), nn.ReLU(), nn.Dropout(dropout_rate),
                    nn.Linear(512, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(dropout_rate),
                    nn.Linear(256, num_classes)
                )
                self.res_branch = nn.Sequential(
                    nn.Linear(input_dim, 128), nn.BatchNorm1d(128), nn.ReLU(),
                    ResidualBlock(128, dropout_rate),
                    ResidualBlock(128, dropout_rate),
                    nn.Linear(128, num_classes)
                )
                self.attention_branch = SelfAttentionBranch(input_dim, num_classes, dropout_rate)
                self.interaction_branch = FeatureInteractionBranch(input_dim, num_classes, dropout_rate)
                
                self.weight_net = nn.Sequential(
                    nn.Linear(input_dim, 32), nn.ReLU(), nn.Dropout(dropout_rate),
                    nn.Linear(32, 5), nn.Softmax(dim=1)
                )
                self.final_fusion = nn.Sequential(
                    nn.Linear(num_classes * 5, 128), nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(dropout_rate),
                    nn.Linear(128, num_classes)
                )
                self.global_weights = nn.Parameter(torch.ones(5) / 5)
                self._init_weights()
            
            def _init_weights(self):
                for module in self.modules():
                    if isinstance(module, nn.Linear):
                        nn.init.xavier_uniform_(module.weight)
                        if module.bias is not None: nn.init.constant_(module.bias, 0)
                    elif isinstance(module, nn.BatchNorm1d):
                        nn.init.constant_(module.weight, 1)
                        nn.init.constant_(module.bias, 0)
            
            def forward(self, x, return_intermediate=False):
                if torch.isnan(x).any() or torch.isinf(x).any():
                    x = torch.nan_to_num(x, nan=0.0, posinf=1.0, neginf=-1.0)
                
                outputs = [
                    self.deep_branch(x), self.wide_branch(x), self.res_branch(x),
                    self.attention_branch(x), self.interaction_branch(x)
                ]
                
                for i, out in enumerate(outputs):
                    if torch.isnan(out).any() or torch.isinf(out).any():
                        outputs[i] = torch.nan_to_num(out, nan=0.0, posinf=1.0, neginf=-1.0)
                
                deep_out, wide_out, res_out, att_out, inter_out = outputs
                
                adaptive_weights = torch.clamp(self.weight_net(x), min=1e-8, max=1.0)
                global_weights = torch.clamp(F.softmax(self.global_weights, dim=0), min=1e-8, max=1.0)
                
                outputs_stack = torch.stack(outputs, dim=2)
                
                weighted_output_adaptive = torch.sum(outputs_stack * adaptive_weights.unsqueeze(1), dim=2)
                weighted_output_global = torch.sum(outputs_stack * global_weights.unsqueeze(0).unsqueeze(0), dim=2)
                weighted_output = 0.6 * weighted_output_adaptive + 0.4 * weighted_output_global
                
                concatenated = torch.cat(outputs, dim=1)
                final_output = self.final_fusion(concatenated)
                
                ensemble_output = 0.7 * final_output + 0.3 * weighted_output
                
                if torch.isnan(ensemble_output).any() or torch.isinf(ensemble_output).any():
                    ensemble_output = torch.nan_to_num(ensemble_output, nan=0.0, posinf=1.0, neginf=-1.0)
                    
                if return_intermediate:
                    return {
                        'ensemble': ensemble_output, 'final_fusion': final_output,
                        'weighted': weighted_output, 'branches': tuple(outputs),
                        'weights': (adaptive_weights, global_weights)
                    }
                return ensemble_output
        
        return Ensemble_Hybrid(input_dim, num_classes)
    
    def _verify_model_weights(self):
        """éªŒè¯æ¨¡å‹æƒé‡æ˜¯å¦æ­£ç¡®åŠ è½½"""
        try:
            # åˆ›å»ºä¸€ä¸ªæµ‹è¯•è¾“å…¥ï¼ˆä½¿ç”¨æ‰¹å¤§å°=2æ¥é˜²æ­¢BatchNormé—®é¢˜ï¼‰
            test_input = torch.randn(2, 64)  # æ¨¡æ‹Ÿ64ä¸ªç‰¹å¾çš„è¾“å…¥ï¼Œæ‰¹å¤§å°=2
            
            with torch.no_grad():
                # æ‰§è¡Œå‰å‘ä¼ æ’­
                output = self.model(test_input)
                
                # æ£€æŸ¥è¾“å‡ºæ˜¯å¦åˆç†
                if torch.isnan(output).any() or torch.isinf(output).any():
                    logger.error("æ¨¡å‹è¾“å‡ºåŒ…å«NaNæˆ–Infå€¼")
                    return False
                
                # æ£€æŸ¥è¾“å‡ºç»´åº¦
                if output.shape != (2, 12):
                    logger.error(f"æ¨¡å‹è¾“å‡ºç»´åº¦ä¸æ­£ç¡®: {output.shape}, æœŸæœ›: (2, 12)")
                    return False
                
                # æ£€æŸ¥è¾“å‡ºæ˜¯å¦ä¸ºå…¨é›¶æˆ–å…¨ç›¸åŒå€¼ï¼ˆéšæœºæƒé‡çš„ç‰¹å¾ï¼‰
                if torch.allclose(output, torch.zeros_like(output), atol=1e-6):
                    logger.warning("æ¨¡å‹è¾“å‡ºå…¨ä¸ºé›¶ï¼Œå¯èƒ½æƒé‡åŠ è½½å¤±è´¥")
                    return False
                
                # æ£€æŸ¥è¾“å‡ºæ˜¯å¦å…·æœ‰åˆç†çš„å˜åŒ–èŒƒå›´
                output_std = torch.std(output)
                if output_std < 1e-6:
                    logger.warning(f"æ¨¡å‹è¾“å‡ºæ–¹å·®è¿‡å°: {output_std}, å¯èƒ½æƒé‡åŠ è½½å¤±è´¥")
                    return False
                
                # æ£€æŸ¥ä¸¤ä¸ªæ ·æœ¬çš„è¾“å‡ºæ˜¯å¦ä¸åŒï¼ˆé¿å…å›ºå®šè¾“å‡ºï¼‰
                if torch.allclose(output[0], output[1], atol=1e-4):
                    logger.warning("æ¨¡å‹è¾“å‡ºå›ºå®šä¸å˜ï¼Œå¯èƒ½æƒé‡åŠ è½½å¤±è´¥")
                    return False
                
                logger.info(f"âœ… æ¨¡å‹æƒé‡éªŒè¯æˆåŠŸ: è¾“å‡ºç»´åº¦={output.shape}, æ–¹å·®={output_std:.6f}")
                return True
                
        except Exception as e:
            logger.error(f"æ¨¡å‹æƒé‡éªŒè¯å¤±è´¥: {e}")
            return False
    
    def _load_preprocessors(self):
        """åŠ è½½é¢„å¤„ç†å™¨"""
        self._load_real_preprocessors()
    
    def _load_real_preprocessors(self):
        """åŠ è½½çœŸå®çš„é¢„å¤„ç†å™¨"""
        # æ ¹æ®Context7æ–‡æ¡£ï¼Œä½¿ç”¨joblibæ˜¯scikit-learnæ¨èçš„åºåˆ—åŒ–æ–¹æ³•
        import joblib
        import warnings
        from sklearn.exceptions import InconsistentVersionWarning
        
        # è®¾ç½®warningè¿‡æ»¤å™¨ä»¥ä¾¿å¤„ç†ç‰ˆæœ¬ä¸åŒ¹é…
        warnings.filterwarnings("ignore", category=InconsistentVersionWarning)
        
        # åŠ è½½StandardScaler
        scaler_path = AI_MODEL_CONFIG['scaler_file']
        try:
            self.scaler = joblib.load(scaler_path)
            logger.info(f"âœ… ScaleråŠ è½½æˆåŠŸ(joblib): {scaler_path}")
        except Exception as e:
            logger.warning(f"joblibå¤±è´¥ï¼Œå°è¯•pickle: {e}")
            try:
                with open(scaler_path, 'rb') as f:
                    self.scaler = pickle.load(f)
                logger.info(f"âœ… ScaleråŠ è½½æˆåŠŸ(pickle): {scaler_path}")
            except Exception as e2:
                logger.warning(f"pickleå¤±è´¥ï¼Œå°è¯•protocol=4: {e2}")
                with open(scaler_path, 'rb') as f:
                    self.scaler = pickle.load(f, encoding='latin1')
                logger.info(f"âœ… ScaleråŠ è½½æˆåŠŸ(latin1): {scaler_path}")
        
        # åŠ è½½ç‰¹å¾é€‰æ‹©å™¨
        selector_path = AI_MODEL_CONFIG['feature_selector_file']
        try:
            self.feature_selector = joblib.load(selector_path)
            logger.info(f"âœ… FeatureSelectoråŠ è½½æˆåŠŸ(joblib): {selector_path}")
        except Exception as e:
            logger.warning(f"joblibå¤±è´¥ï¼Œå°è¯•pickle: {e}")
            try:
                with open(selector_path, 'rb') as f:
                    self.feature_selector = pickle.load(f)
                logger.info(f"âœ… FeatureSelectoråŠ è½½æˆåŠŸ(pickle): {selector_path}")
            except Exception as e2:
                logger.warning(f"pickleå¤±è´¥ï¼Œå°è¯•latin1: {e2}")
                with open(selector_path, 'rb') as f:
                    self.feature_selector = pickle.load(f, encoding='latin1')
                logger.info(f"âœ… FeatureSelectoråŠ è½½æˆåŠŸ(latin1): {selector_path}")
        
        # åŠ è½½æ ‡ç­¾ç¼–ç å™¨
        encoder_path = AI_MODEL_CONFIG['label_encoder_file']
        try:
            self.label_encoder = joblib.load(encoder_path)
            logger.info(f"âœ… LabelEncoderåŠ è½½æˆåŠŸ(joblib): {encoder_path}")
        except Exception as e:
            logger.warning(f"joblibå¤±è´¥ï¼Œå°è¯•pickle: {e}")
            try:
                with open(encoder_path, 'rb') as f:
                    self.label_encoder = pickle.load(f)
                logger.info(f"âœ… LabelEncoderåŠ è½½æˆåŠŸ(pickle): {encoder_path}")
            except Exception as e2:
                logger.warning(f"pickleå¤±è´¥ï¼Œå°è¯•latin1: {e2}")
                with open(encoder_path, 'rb') as f:
                    self.label_encoder = pickle.load(f, encoding='latin1')
                logger.info(f"âœ… LabelEncoderåŠ è½½æˆåŠŸ(latin1): {encoder_path}")
    
    
    def _load_metadata(self):
        """åŠ è½½æ¨¡å‹å…ƒæ•°æ®"""
        # åŠ è½½æ¨¡å‹ä¿¡æ¯
        info_path = AI_MODEL_CONFIG['model_info_file']
        with open(info_path, 'r') as f:
            self.model_info = json.load(f)
        logger.info(f"âœ… æ¨¡å‹ä¿¡æ¯åŠ è½½æˆåŠŸ: {self.model_info['num_classes']}ä¸ªå¨èƒç±»åˆ«")
        
        # åŠ è½½é€‰æ‹©çš„ç‰¹å¾
        features_path = AI_MODEL_CONFIG['selected_features_file']
        with open(features_path, 'r') as f:
            self.selected_features = json.load(f)
        logger.info(f"âœ… ç‰¹å¾ä¿¡æ¯åŠ è½½æˆåŠŸ: {len(self.selected_features)}ä¸ªç‰¹å¾")
    
    def _load_inference_data(self):
        """åŠ è½½æ¨ç†æµ‹è¯•æ•°æ®"""
        try:
            data_path = AI_MODEL_CONFIG['inference_data_file']
            self.inference_data = torch.load(data_path, map_location='cpu')
            logger.info(f"âœ… æ¨ç†æ•°æ®åŠ è½½æˆåŠŸ: {len(self.inference_data)}ä¸ªçœŸå®æ ·æœ¬")
                
        except Exception as e:
            logger.error(f"âŒ æ— æ³•åŠ è½½æ¨ç†æ•°æ®: {e}")
            raise RuntimeError(f"æ— æ³•åŠ è½½å¿…éœ€çš„æ¨ç†æ•°æ®æ–‡ä»¶: {data_path}")
    
    
    def _get_true_labels(self) -> List[str]:
        """é‡å»ºçœŸå®æ ‡ç­¾æ˜ å°„ï¼ˆåŸºäºæŠ½æ ·è„šæœ¬çš„shuffleé€»è¾‘ï¼‰"""
        # é‡å»ºæ ‡ç­¾åˆ—è¡¨ï¼ˆä¸æ‰€æœ‰åˆ†æè„šæœ¬ä¸­ä½¿ç”¨çš„é€»è¾‘ä¸€è‡´ï¼‰
        labels = []
        labels.extend(['Benign'] * 120)  # å‰120ä¸ªæ˜¯Benign
        threat_classes = ['Bot', 'DDoS', 'DoS GoldenEye', 'DoS Hulk', 'DoS Slowhttptest', 
                         'DoS slowloris', 'FTP-Patator', 'PortScan', 'Rare_Attack', 'SSH-Patator', 'Web Attack  Brute Force']
        for class_name in threat_classes:  # å…¶ä½™ç±»åˆ«æ¯ä¸ª10ä¸ª
            labels.extend([class_name] * 10)
        
        # ä½¿ç”¨å›ºå®šç§å­åº”ç”¨shuffleï¼ˆä¸æŠ½æ ·è„šæœ¬ä¸€è‡´ï¼‰
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä¿å­˜éšæœºçŠ¶æ€ï¼Œé¿å…æ¯æ¬¡è°ƒç”¨éƒ½é‡ç½®éšæœºç§å­
        random_state = np.random.get_state()
        np.random.seed(42)
        shuffled_indices = np.random.permutation(len(labels))
        shuffled_labels = [labels[i] for i in shuffled_indices]
        np.random.set_state(random_state)  # æ¢å¤éšæœºçŠ¶æ€
        
        return shuffled_labels
    
    def get_random_attack_sample(self) -> Tuple[np.ndarray, str]:
        """éšæœºè·å–ä¸€ä¸ªæ”»å‡»æ ·æœ¬"""
        if self.inference_data is None:
            raise RuntimeError("æ¨ç†æ•°æ®æœªåŠ è½½")
        
        # è·å–çœŸå®æ ‡ç­¾æ˜ å°„
        true_labels = self._get_true_labels()
        
        # æ‰¾åˆ°æ‰€æœ‰æ”»å‡»æ ·æœ¬çš„ç´¢å¼•
        attack_indices = [i for i, label in enumerate(true_labels) if label != 'Benign']
        
        if not attack_indices:
            raise RuntimeError("æ²¡æœ‰æ‰¾åˆ°æ”»å‡»æ ·æœ¬")
        
        # éšæœºé€‰æ‹©ä¸€ä¸ªæ”»å‡»æ ·æœ¬
        sample_idx = np.random.choice(attack_indices)
        true_label = true_labels[sample_idx]
        
        # æå–ç‰¹å¾ï¼ˆç›´æ¥ä½¿ç”¨çœŸå®çš„inference_data.pt tensorï¼‰
        features = self.inference_data[sample_idx].numpy()
        
        # ç¡®ä¿featuresæ˜¯1Dæ•°ç»„
        if features.ndim > 1:
            features = features.flatten()
        
        return features, true_label
    
    def predict_threat(self, features: np.ndarray, is_preprocessed: bool = False, strategy: str = "original") -> Dict:
        """æ‰§è¡Œå¨èƒé¢„æµ‹"""
        try:
            # æ£€æŸ¥æ˜¯å¦ä¸ºå·²é¢„å¤„ç†æ•°æ®
            if is_preprocessed:
                processed_features = features
                logger.debug("ä½¿ç”¨å·²é¢„å¤„ç†æ•°æ®ï¼Œè·³è¿‡é¢„å¤„ç†æ­¥éª¤")
            else:
                # å¯¹åŸå§‹æ•°æ®è¿›è¡Œé¢„å¤„ç†
                processed_features = self._preprocess_features(features)
                logger.debug("å¯¹åŸå§‹æ•°æ®è¿›è¡Œé¢„å¤„ç†")
            
            # æ¨¡å‹æ¨ç†
            with torch.no_grad():
                input_tensor = torch.FloatTensor(processed_features).unsqueeze(0)
                outputs = self.model(input_tensor)
                probabilities = torch.softmax(outputs, dim=1)
                
                # åº”ç”¨æ”¹è¿›çš„å†³ç­–ç­–ç•¥
                predicted_class_idx, confidence, predicted_class = self._apply_improved_decision_strategy(probabilities[0], strategy)
                
                # è®°å½•åŸå§‹æœ€é«˜æ¦‚ç‡é¢„æµ‹ä¾›å¯¹æ¯”
                original_predicted_idx = torch.argmax(probabilities, dim=1).item()
                original_predicted_class = self.label_encoder.inverse_transform([original_predicted_idx])[0]
                
                if predicted_class != original_predicted_class:
                    logger.info(f"å†³ç­–ç­–ç•¥è°ƒæ•´: åŸå§‹é¢„æµ‹={original_predicted_class}, è°ƒæ•´å={predicted_class}")
                
                # è°ƒè¯•ä¿¡æ¯ï¼šè®°å½•æ‰€æœ‰ç±»åˆ«æ¦‚ç‡
                logger.debug(f"é¢„æµ‹ç»“æœ: {predicted_class} (ç´¢å¼•: {predicted_class_idx}, ç½®ä¿¡åº¦: {confidence:.4f})")
                logger.debug(f"æ‰€æœ‰ç±»åˆ«æ¦‚ç‡: {dict(zip(self.model_info['classes'], probabilities[0].tolist()))}")
                
                # ç¡®å®šå“åº”çº§åˆ«
                response_level = self._determine_response_level(confidence)
                
                return {
                    "predicted_class": predicted_class,
                    "confidence": confidence,
                    "response_level": response_level,
                    "all_probabilities": probabilities[0].tolist(),
                    "class_names": self.model_info['classes']
                }
                
        except Exception as e:
            logger.error(f"âŒ å¨èƒé¢„æµ‹å¤±è´¥: {e}")
            raise
    
    def _preprocess_features(self, features: np.ndarray) -> np.ndarray:
        """é¢„å¤„ç†ç‰¹å¾æ•°æ® - ä¿®å¤ç»´åº¦ä¸åŒ¹é…é—®é¢˜"""
        # ç¡®ä¿è¾“å…¥æ˜¯2Dæ•°ç»„
        if features.ndim == 1:
            features = features.reshape(1, -1)
        
        logger.debug(f"åŸå§‹ç‰¹å¾ç»´åº¦: {features.shape}")
        
        # æ£€æŸ¥ç‰¹å¾é€‰æ‹©å™¨çš„æœŸæœ›è¾“å…¥ç»´åº¦
        expected_features_for_selector = getattr(self.feature_selector, 'n_features_in_', 65)
        
        # å…³é”®ä¿®å¤ï¼šå¦‚æœæˆ‘ä»¬çš„æ•°æ®åªæœ‰64ç»´ï¼Œä½†ç‰¹å¾é€‰æ‹©å™¨æœŸæœ›65ç»´è¾“å…¥
        if features.shape[1] == 64 and expected_features_for_selector == 65:
            # æ·»åŠ ä¸€ä¸ªé¢å¤–ç‰¹å¾ï¼ˆä½¿ç”¨å‡å€¼æˆ–é›¶å€¼ï¼‰
            # è¿™é‡Œä½¿ç”¨é›¶å€¼ï¼Œå› ä¸ºå®ƒä¸ä¼šå½±å“ç‰¹å¾é€‰æ‹©çš„ç»“æœ
            extra_feature = np.zeros((features.shape[0], 1))
            features = np.concatenate([features, extra_feature], axis=1)
            logger.info(f"æ·»åŠ ä¸€ä¸ªé›¶å€¼ç‰¹å¾ä»¥åŒ¹é…ç‰¹å¾é€‰æ‹©å™¨: {features.shape}")
        
        # å…¶ä»–ç»´åº¦ä¸åŒ¹é…æƒ…å†µçš„å¤„ç†
        elif features.shape[1] != expected_features_for_selector:
            logger.warning(f"ç‰¹å¾ç»´åº¦ä¸åŒ¹é…: å®é™…{features.shape[1]}, ç‰¹å¾é€‰æ‹©å™¨æœŸæœ›{expected_features_for_selector}")
            
            if features.shape[1] < expected_features_for_selector:
                # å¦‚æœç‰¹å¾ä¸è¶³ï¼Œç”¨é›¶å€¼å¡«å……
                padding = np.zeros((features.shape[0], expected_features_for_selector - features.shape[1]))
                features = np.concatenate([features, padding], axis=1)
                logger.info(f"ç‰¹å¾å¡«å……åˆ°{expected_features_for_selector}ç»´: {features.shape}")
            elif features.shape[1] > expected_features_for_selector:
                # å¦‚æœç‰¹å¾è¿‡å¤šï¼Œæˆªå–å‰Nä¸ª
                features = features[:, :expected_features_for_selector]
                logger.info(f"ç‰¹å¾æˆªå–åˆ°{expected_features_for_selector}ç»´: {features.shape}")
        
        # æ­¥éª¤1: ç‰¹å¾é€‰æ‹©ï¼ˆä»65ç»´é€‰æ‹©64ç»´ï¼‰
        try:
            selected_features = self.feature_selector.transform(features)
            logger.debug(f"ç‰¹å¾é€‰æ‹©åç»´åº¦: {selected_features.shape}")
        except Exception as e:
            logger.warning(f"ç‰¹å¾é€‰æ‹©å¤±è´¥: {e}ï¼Œæ‰‹åŠ¨é€‰æ‹©å‰64ä¸ªç‰¹å¾")
            n_select = min(64, features.shape[1])
            selected_features = features[:, :n_select]
        
        # æ­¥éª¤2: æ ‡å‡†åŒ–ï¼ˆå¯¹64ç»´ç‰¹å¾è¿›è¡Œæ ‡å‡†åŒ–ï¼‰
        try:
            scaled_features = self.scaler.transform(selected_features)
            logger.debug(f"æ ‡å‡†åŒ–åç»´åº¦: {scaled_features.shape}")
        except Exception as e:
            logger.warning(f"Scalerå˜æ¢å¤±è´¥: {e}ï¼Œä½¿ç”¨æœªæ ‡å‡†åŒ–ç‰¹å¾")
            scaled_features = selected_features
        
        return scaled_features.flatten()
    
    def _apply_improved_decision_strategy(self, probabilities: torch.Tensor, strategy: str = "original") -> tuple:
        """åº”ç”¨æ”¹è¿›çš„å†³ç­–ç­–ç•¥æ¥æé«˜æ”»å‡»æ£€æµ‹å‡†ç¡®ç‡"""
        # è·å–æ‰€æœ‰ç±»åˆ«åç§°
        class_names = self.model_info['classes']
        
        # æŒ‰æ¦‚ç‡æ’åº
        sorted_indices = torch.argsort(probabilities, descending=True)
        
        # è·å–Benignç±»åˆ«çš„ç´¢å¼•å’Œæ¦‚ç‡
        benign_idx = class_names.index('Benign')
        benign_prob = probabilities[benign_idx].item()
        
        if strategy == "original":
            # ç­–ç•¥2ï¼šç›´æ¥ä½¿ç”¨æ¨¡å‹çš„åŸå§‹é¢„æµ‹ç»“æœ
            predicted_class_idx = sorted_indices[0].item()
            confidence = probabilities[predicted_class_idx].item()
            predicted_class = self.label_encoder.inverse_transform([predicted_class_idx])[0]
            return predicted_class_idx, confidence, predicted_class
            
        elif strategy == "attack_vs_benign":
            # ç­–ç•¥3ï¼šæ¯”è¾ƒæ”»å‡»ç±»åˆ«æ€»æ¦‚ç‡ vs Benignæ¦‚ç‡
            # è®¡ç®—æ‰€æœ‰æ”»å‡»ç±»åˆ«çš„æ¦‚ç‡æ€»å’Œ
            attack_prob_sum = 0.0
            for i, class_name in enumerate(class_names):
                if class_name != 'Benign':
                    attack_prob_sum += probabilities[i].item()
            
            if attack_prob_sum > benign_prob:
                # æ”»å‡»æ¦‚ç‡æ€»å’Œæ›´é«˜ï¼Œé€‰æ‹©æ¦‚ç‡æœ€é«˜çš„æ”»å‡»ç±»åˆ«
                for idx in sorted_indices:
                    if class_names[idx] != 'Benign':
                        predicted_class_idx = idx.item()
                        confidence = probabilities[predicted_class_idx].item()
                        predicted_class = self.label_encoder.inverse_transform([predicted_class_idx])[0]
                        return predicted_class_idx, confidence, predicted_class
            else:
                # Benignæ¦‚ç‡æ›´é«˜ï¼Œé€‰æ‹©Benign
                predicted_class_idx = benign_idx
                confidence = benign_prob
                predicted_class = 'Benign'
                return predicted_class_idx, confidence, predicted_class
        
        else:
            # é»˜è®¤ä½¿ç”¨åŸå§‹ç­–ç•¥
            predicted_class_idx = sorted_indices[0].item()
            confidence = probabilities[predicted_class_idx].item()
            predicted_class = self.label_encoder.inverse_transform([predicted_class_idx])[0]
            return predicted_class_idx, confidence, predicted_class
    
    def _determine_response_level(self, confidence: float) -> str:
        """æ ¹æ®ç½®ä¿¡åº¦ç¡®å®šå“åº”çº§åˆ«"""
        if confidence > THREAT_THRESHOLDS['high_confidence']:
            return "automatic_response"
        elif confidence > THREAT_THRESHOLDS['medium_high']:
            return "auto_create_proposal"
        elif confidence > THREAT_THRESHOLDS['medium_low']:
            return "manual_decision_alert"
        else:
            return "silent_logging"
    
    def simulate_attack_detection(self) -> Dict:
        """æ¨¡æ‹Ÿæ”»å‡»æ£€æµ‹å®Œæ•´æµç¨‹"""
        try:
            # è·å–éšæœºæ”»å‡»æ ·æœ¬
            features, true_label = self.get_random_attack_sample()
            
            # æ‰§è¡Œé¢„æµ‹ï¼ˆinference_dataä¸­çš„æ•°æ®å·²é¢„å¤„ç†ï¼‰
            prediction_result = self.predict_threat(features, is_preprocessed=True)
            
            # æ·»åŠ çœŸå®æ ‡ç­¾ä¿¡æ¯
            prediction_result['true_label'] = true_label
            prediction_result['sample_features'] = features.tolist()
            
            logger.info(f"ğŸ¯ æ¨¡æ‹Ÿæ”»å‡»æ£€æµ‹å®Œæˆ:")
            logger.info(f"   çœŸå®æ ‡ç­¾: {true_label}")
            logger.info(f"   é¢„æµ‹ç±»åˆ«: {prediction_result['predicted_class']}")
            logger.info(f"   ç½®ä¿¡åº¦: {prediction_result['confidence']:.4f}")
            logger.info(f"   å“åº”çº§åˆ«: {prediction_result['response_level']}")
            
            return prediction_result
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡æ‹Ÿæ”»å‡»æ£€æµ‹å¤±è´¥: {e}")
            raise
    
    def get_model_info(self) -> Dict:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        # å¤„ç† inference_data çš„é•¿åº¦è®¡ç®—
        inference_samples = 0
        if self.inference_data is not None:
            if hasattr(self.inference_data, 'shape'):
                # å¦‚æœæ˜¯ tensorï¼Œä½¿ç”¨ shape[0]
                inference_samples = self.inference_data.shape[0]
            elif hasattr(self.inference_data, '__len__'):
                # å¦‚æœæ˜¯åˆ—è¡¨æˆ–å…¶ä»–å¯è¿­ä»£å¯¹è±¡
                inference_samples = len(self.inference_data)
        
        return {
            "model_info": self.model_info,
            "feature_count": len(self.selected_features) if self.selected_features else 0,
            "threat_classes": self.model_info['classes'] if self.model_info else [],
            "thresholds": THREAT_THRESHOLDS,
            "inference_samples": inference_samples
        }

# å…¨å±€æ¨¡å‹å®ä¾‹
threat_model = None

def get_threat_model() -> ThreatDetectionModel:
    """è·å–å¨èƒæ£€æµ‹æ¨¡å‹å•ä¾‹"""
    global threat_model
    if threat_model is None:
        threat_model = ThreatDetectionModel()
    return threat_model

def init_threat_model():
    """åˆå§‹åŒ–å¨èƒæ£€æµ‹æ¨¡å‹"""
    global threat_model
    threat_model = ThreatDetectionModel()
    return threat_model